#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æµ‹è¯•å¤šæ¨¡æ€NotetakerAgentçš„çŸ¥è¯†ç®¡ç†åŠŸèƒ½

éªŒè¯åŸºäºAgenticXæ¡†æ¶çš„çœŸæ­£å¤šæ¨¡æ€LLMé©±åŠ¨çš„NotetakerAgentå®ç°
"""

import asyncio
from loguru import logger
import os
import sys
from pathlib import Path
from typing import Dict, Any, List

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# åŠ è½½.envæ–‡ä»¶
try:
    from dotenv import load_dotenv
    env_path = project_root / '.env'
    if env_path.exists():
        load_dotenv(env_path)
        print(f"å·²åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶: {env_path}")
except ImportError:
    print("æœªå®‰è£…python-dotenvï¼Œè·³è¿‡.envæ–‡ä»¶åŠ è½½")

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
from agenticx.llms.bailian_provider import BailianProvider
from agenticx.core.event_bus import EventBus
from agents.notetaker_agent import NotetakerAgent
from config import AgentConfig
from utils import setup_logger

# è®¾ç½®æ—¥å¿—
logger = setup_logger("test_multimodal_notetaker", level="INFO")


async def _validate_knowledge_granularity(results: List[Dict[str, Any]], query_case: Dict[str, Any]) -> Dict[str, Any]:
    """éªŒè¯çŸ¥è¯†æ£€ç´¢ç»“æœçš„ç²’åº¦ç‰¹å¾"""
    granularity = query_case.get('granularity', 'unknown')
    expected_features = query_case.get('expected_features', [])
    expected_granularities = query_case.get('expected_granularities', [])
    expected_domains = query_case.get('expected_domains', [])
    
    validation_result = {
        'valid': True,
        'message': '',
        'details': {}
    }
    
    if not results:
        validation_result['valid'] = False
        validation_result['message'] = 'æœªæ‰¾åˆ°ä»»ä½•çŸ¥è¯†é¡¹'
        return validation_result
    
    # éªŒè¯ç‰¹å®šç²’åº¦çš„ç‰¹å¾
    if expected_features:
        feature_found_count = 0
        total_items = len(results)
        
        for result in results:
            content = result.get('content', {})
            if isinstance(content, dict):
                for feature in expected_features:
                    if feature in content:
                        feature_found_count += 1
                        break
        
        feature_coverage = feature_found_count / total_items if total_items > 0 else 0
        validation_result['details']['feature_coverage'] = feature_coverage
        
        if feature_coverage >= 0.5:  # è‡³å°‘50%çš„ç»“æœåŒ…å«é¢„æœŸç‰¹å¾
            validation_result['message'] += f'{granularity}ç²’åº¦ç‰¹å¾è¦†ç›–ç‡: {feature_coverage:.1%}'
        else:
            validation_result['valid'] = False
            validation_result['message'] += f'{granularity}ç²’åº¦ç‰¹å¾è¦†ç›–ç‡è¿‡ä½: {feature_coverage:.1%}'
    
    # éªŒè¯è·¨ç²’åº¦æ£€ç´¢
    if expected_granularities:
        found_granularities = set()
        for result in results:
            tags = result.get('tags', [])
            for granularity_tag in expected_granularities:
                if granularity_tag in tags:
                    found_granularities.add(granularity_tag)
        
        coverage = len(found_granularities) / len(expected_granularities)
        validation_result['details']['granularity_coverage'] = coverage
        
        if coverage >= 0.6:  # è‡³å°‘è¦†ç›–60%çš„é¢„æœŸç²’åº¦
            validation_result['message'] += f'è·¨ç²’åº¦è¦†ç›–ç‡: {coverage:.1%}'
        else:
            validation_result['valid'] = False
            validation_result['message'] += f'è·¨ç²’åº¦è¦†ç›–ç‡ä¸è¶³: {coverage:.1%}'
    
    # éªŒè¯é¢†åŸŸåˆ†å¸ƒ
    if expected_domains:
        found_domains = set()
        for result in results:
            domain = result.get('domain', '')
            if domain in expected_domains:
                found_domains.add(domain)
        
        domain_coverage = len(found_domains) / len(expected_domains)
        validation_result['details']['domain_coverage'] = domain_coverage
        
        if domain_coverage >= 0.5:  # è‡³å°‘è¦†ç›–50%çš„é¢„æœŸé¢†åŸŸ
            validation_result['message'] += f', é¢†åŸŸè¦†ç›–ç‡: {domain_coverage:.1%}'
        else:
            validation_result['message'] += f', é¢†åŸŸè¦†ç›–ç‡è¾ƒä½: {domain_coverage:.1%}'
    
    return validation_result


def _analyze_granularity_distribution(results: List[Dict[str, Any]]) -> Dict[str, int]:
    """åˆ†æçŸ¥è¯†æ£€ç´¢ç»“æœçš„ç²’åº¦åˆ†å¸ƒ"""
    granularity_stats = {
        'complete_task': 0,
        'subtask': 0,
        'atomic_operation': 0,
        'other': 0
    }
    
    for result in results:
        tags = result.get('tags', [])
        knowledge_type = result.get('type', '')
        
        # æ ¹æ®æ ‡ç­¾å’Œç±»å‹åˆ¤æ–­ç²’åº¦
        if 'complete_task' in tags or knowledge_type == 'task_workflow':
            granularity_stats['complete_task'] += 1
        elif 'subtask' in tags or knowledge_type == 'best_practice':
            granularity_stats['subtask'] += 1
        elif 'atomic' in tags or knowledge_type == 'action_pattern':
            granularity_stats['atomic_operation'] += 1
        else:
            granularity_stats['other'] += 1
    
    # åªè¿”å›éé›¶çš„ç»Ÿè®¡
    return {k: v for k, v in granularity_stats.items() if v > 0}

async def test_multimodal_knowledge_management():
    """æµ‹è¯•å¤šæ¨¡æ€çŸ¥è¯†ç®¡ç†åŠŸèƒ½"""
    
    logger.info("ğŸš€ å¼€å§‹æµ‹è¯•å¤šæ¨¡æ€NotetakerAgent")
    
    # åˆå§‹åŒ–LLMæä¾›è€…ï¼ˆä½¿ç”¨ç™¾ç‚¼å¤šæ¨¡æ€æ¨¡å‹ï¼‰
    try:
        # ä»ç¯å¢ƒå˜é‡è·å–ç™¾ç‚¼APIå¯†é’¥
        api_key = os.getenv('BAILIAN_API_KEY')
        if not api_key:
            logger.warning("ğŸ”„ æœªè®¾ç½®BAILIAN_API_KEYç¯å¢ƒå˜é‡ï¼Œå°†æµ‹è¯•æ— LLMæ¨¡å¼")
            llm_provider = None
        else:
            llm_provider = BailianProvider(
                api_key=api_key,
                model="qwen-vl-max",  # ä½¿ç”¨å¤šæ¨¡æ€æ¨¡å‹
                temperature=0.3
            )
            logger.info(f"ğŸ¤– ç™¾ç‚¼å¤šæ¨¡æ€LLMæä¾›è€…åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: qwen-vl-max")
    except Exception as e:
        logger.error(f"âŒ LLMæä¾›è€…åˆå§‹åŒ–å¤±è´¥: {e}")
        llm_provider = None
    
    # åˆå§‹åŒ–äº‹ä»¶æ€»çº¿
    event_bus = EventBus()
    
    # åˆ›å»ºNotetakerAgenté…ç½®
    agent_config = AgentConfig(
        id="test_notetaker",
        name="TestNotetakerAgent",
        role="notetaker",
        goal="æµ‹è¯•å¤šæ¨¡æ€LLMé©±åŠ¨çš„çŸ¥è¯†ç®¡ç†",
        backstory="æˆ‘æ˜¯ä¸€ä¸ªæµ‹è¯•ç”¨çš„çŸ¥è¯†è®°å½•æ™ºèƒ½ä½“ï¼Œèƒ½å¤Ÿä½¿ç”¨å¤šæ¨¡æ€LLMæ™ºèƒ½æå–å’Œç®¡ç†çŸ¥è¯†ã€‚"
    )
    
    # åˆå§‹åŒ–NotetakerAgent
    notetaker_agent = NotetakerAgent(
        llm_provider=llm_provider,
        agent_id="test_notetaker",
        event_bus=event_bus,
        agent_config=agent_config
    )
    
    logger.info("NotetakerAgentåˆå§‹åŒ–å®Œæˆ")
    
    # æµ‹è¯•ç”¨ä¾‹ - å¤šç²’åº¦çŸ¥è¯†æ•è·ã€æŸ¥è¯¢ã€ç»„ç»‡
    test_cases = [
        {
            "name": "æµ‹è¯•1: å®Œæ•´ä»»åŠ¡çº§åˆ«çŸ¥è¯† - ç”µå•†è´­ç‰©æµç¨‹",
            "granularity": "complete_task",
            "task_context": {
                "task_type": "capture",
                "knowledge_data": {
                    "type": "task_workflow",
                    "title": "æ·˜å®è´­ç‰©å®Œæ•´æµç¨‹æœ€ä½³å®è·µ",
                    "description": "ç”¨æˆ·åœ¨æ·˜å®è´­ä¹°å•†å“çš„å®Œæ•´ä»»åŠ¡æµç¨‹",
                    "content": {
                        "task_description": "å¸®æˆ‘åœ¨æ·˜å®ä¸Šä¹°ä¸€ä»¶è¡£æœ",
                        "workflow_steps": [
                            "æ‰“å¼€æ·˜å®åº”ç”¨",
                            "ç™»å½•è´¦æˆ·",
                            "æœç´¢å•†å“",
                            "ç­›é€‰å’Œæ¯”è¾ƒ",
                            "é€‰æ‹©å•†å“",
                            "åŠ å…¥è´­ç‰©è½¦",
                            "ç¡®è®¤è®¢å•",
                            "é€‰æ‹©æ”¯ä»˜æ–¹å¼",
                            "å®Œæˆæ”¯ä»˜"
                        ],
                        "success_rate": 0.92,
                        "average_duration": 180,
                        "complexity_level": "high",
                        "user_satisfaction": 0.88,
                        "common_challenges": [
                            "å•†å“é€‰æ‹©å›°éš¾",
                            "æ”¯ä»˜æµç¨‹å¤æ‚",
                            "ç½‘ç»œå»¶è¿Ÿå½±å“"
                        ],
                        "optimization_tips": [
                            "é¢„å…ˆå‡†å¤‡è´­ç‰©æ¸…å•",
                            "ä½¿ç”¨æ”¶è—å¤¹ç®¡ç†å•†å“",
                            "é€‰æ‹©åˆé€‚çš„æ”¯ä»˜æ–¹å¼"
                        ]
                    },
                    "domain": "e_commerce",
                    "tags": ["shopping", "complete_task", "e_commerce", "workflow"],
                    "source": "ManagerAgent"
                }
            }
        },
        {
            "name": "æµ‹è¯•2: å­ä»»åŠ¡çº§åˆ«çŸ¥è¯† - ç‚¹å‡»æ“ä½œæœ€ä½³å®è·µ",
            "granularity": "subtask",
            "task_context": {
                "task_type": "capture",
                "knowledge_data": {
                    "type": "best_practice",
                    "title": "ç§»åŠ¨è®¾å¤‡ç‚¹å‡»æ“ä½œæœ€ä½³å®è·µ",
                    "description": "Manageræ‹†è§£åçš„ç‚¹å‡»å­ä»»åŠ¡æ‰§è¡ŒæŠ€å·§",
                    "content": {
                        "subtask_type": "click_operation",
                        "parent_task": "å•†å“é€‰æ‹©å’Œè´­ä¹°",
                        "success_rate": 0.95,
                        "efficiency_score": 0.88,
                        "best_practices": [
                            "ç¡®ä¿ç›®æ ‡å…ƒç´ å¯è§",
                            "ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ",
                            "ä½¿ç”¨ç²¾ç¡®çš„åæ ‡å®šä½",
                            "éªŒè¯ç‚¹å‡»åçš„çŠ¶æ€å˜åŒ–"
                        ],
                        "common_errors": [
                            "å…ƒç´ æœªæ‰¾åˆ°",
                            "ç‚¹å‡»ä½ç½®åç§»",
                            "é¡µé¢æœªå®Œå…¨åŠ è½½"
                        ],
                        "applicable_scenarios": [
                            "æŒ‰é’®ç‚¹å‡»",
                            "é“¾æ¥ç‚¹å‡»",
                            "å›¾æ ‡ç‚¹å‡»",
                            "åˆ—è¡¨é¡¹é€‰æ‹©"
                        ],
                        "conditions": "é€‚ç”¨äºæ‰€æœ‰ç‚¹å‡»æ“ä½œ",
                        "confidence": 0.9
                    },
                    "domain": "mobile_automation",
                    "tags": ["click", "subtask", "best_practice", "mobile"],
                    "source": "ExecutorAgent"
                }
            }
        },
        {
            "name": "æµ‹è¯•3: åŸå­æ“ä½œçº§åˆ«çŸ¥è¯† - tapåæ ‡ä¼˜åŒ–",
            "granularity": "atomic_operation",
            "task_context": {
                "task_type": "capture",
                "knowledge_data": {
                    "type": "action_pattern",
                    "title": "tap(x,y)åæ ‡ç²¾åº¦ä¼˜åŒ–æ¨¡å¼",
                    "description": "åŸå­çº§åˆ«çš„tapæ“ä½œå‚æ•°ä¼˜åŒ–çŸ¥è¯†",
                    "content": {
                        "operation_type": "tap",
                        "parameters": {
                            "coordinate_precision": 0.1,
                            "tap_duration": 100,
                            "pressure_level": "medium"
                        },
                        "optimization_strategies": [
                            "ä¸­å¿ƒç‚¹åç§»è¡¥å¿",
                            "å…ƒç´ è¾¹ç•Œæ£€æµ‹",
                            "å¤šç‚¹é‡‡æ ·éªŒè¯",
                            "åŠ¨æ€åæ ‡è°ƒæ•´"
                        ],
                        "performance_metrics": {
                            "accuracy_rate": 0.98,
                            "response_time": 50,
                            "retry_rate": 0.02
                        },
                        "device_compatibility": [
                            "Android 9+",
                            "iOS 13+",
                            "ä¸åŒå±å¹•åˆ†è¾¨ç‡"
                        ],
                        "error_handling": {
                            "coordinate_out_of_bounds": "è¾¹ç•Œè£å‰ª",
                            "element_moved": "é‡æ–°å®šä½",
                            "tap_failed": "é‡è¯•æœºåˆ¶"
                        }
                    },
                    "domain": "atomic_operations",
                    "tags": ["tap", "atomic", "coordinates", "optimization"],
                    "source": "low_level_executor"
                }
            }
        },
        {
            "name": "æµ‹è¯•2: æ•è·é”™è¯¯è§£å†³æ–¹æ¡ˆ",
            "task_context": {
                "task_type": "capture",
                "knowledge_data": {
                    "type": "error_solution",
                    "content": {
                        "error_type": "element_not_found",
                        "error_frequency": 0.15,
                        "solutions": [
                            "å¢åŠ ç­‰å¾…æ—¶é—´",
                            "ä½¿ç”¨å¤‡ç”¨å®šä½ç­–ç•¥",
                            "æ£€æŸ¥é¡µé¢åŠ è½½çŠ¶æ€"
                        ],
                        "prevention": [
                            "é¢„å…ˆéªŒè¯å…ƒç´ å­˜åœ¨",
                            "ä½¿ç”¨åŠ¨æ€ç­‰å¾…æœºåˆ¶"
                        ],
                        "success_rate_after_fix": 0.92
                    },
                    "source": "ActionReflectorAgent"
                }
            }
        },
        {
            "name": "æµ‹è¯•3: æ•è·æœ€ä½³å®è·µ",
            "task_context": {
                "task_type": "capture",
                "knowledge_data": {
                    "type": "best_practice",
                    "content": {
                        "area": "mobile_automation",
                        "practices": [
                            "æ“ä½œå‰å…ˆæˆªå›¾ä¿å­˜çŠ¶æ€",
                            "ä½¿ç”¨å¤šæ¨¡æ€LLMè¿›è¡Œæ™ºèƒ½åˆ†æ",
                            "å»ºç«‹æ“ä½œå‰åå¯¹æ¯”æœºåˆ¶",
                            "å®æ–½å¤šæ¨¡å‹é™çº§ç­–ç•¥"
                        ],
                        "benefits": [
                            "æé«˜æ“ä½œæˆåŠŸç‡",
                            "å¢å¼ºç³»ç»Ÿå¯é æ€§",
                            "æ”¹å–„ç”¨æˆ·ä½“éªŒ"
                        ],
                        "applicable_scenarios": "æ‰€æœ‰ç§»åŠ¨è®¾å¤‡è‡ªåŠ¨åŒ–åœºæ™¯"
                    },
                    "source": "ManagerAgent"
                }
            }
        },
        {
            "name": "æµ‹è¯•4: æ•è·æ€§èƒ½æ´å¯Ÿ",
            "task_context": {
                "task_type": "capture",
                "knowledge_data": {
                    "type": "performance_insight",
                    "content": {
                        "metric": "execution_time",
                        "average_time": 2.3,
                        "optimization_suggestions": [
                            "å¹¶è¡Œæ‰§è¡Œéä¾èµ–æ“ä½œ",
                            "ç¼“å­˜å¸¸ç”¨å…ƒç´ å®šä½",
                            "ä¼˜åŒ–æˆªå›¾å¤„ç†æµç¨‹"
                        ],
                        "performance_trends": {
                            "improving": True,
                            "trend_description": "æ‰§è¡Œæ—¶é—´é€æ­¥ä¼˜åŒ–"
                        }
                    },
                    "source": "system_monitor"
                }
            }
        }
    ]
    
    # æ‰§è¡ŒçŸ¥è¯†æ•è·æµ‹è¯•
    logger.info("\nğŸ“ å¼€å§‹çŸ¥è¯†æ•è·æµ‹è¯•")
    captured_knowledge_ids = []
    
    for i, test_case in enumerate(test_cases, 1):
        logger.info(f"\n{'='*50}")
        logger.info(f"çŸ¥è¯†æ•è· {i}: {test_case['name']}")
        logger.info(f"{'='*50}")
        
        try:
            # æ‰§è¡ŒçŸ¥è¯†æ•è·
            result = await notetaker_agent._execute_task_impl(test_case['task_context'])
            
            if result.get('success', False):
                knowledge_id = result.get('knowledge_id')
                knowledge_type = result.get('knowledge_type')
                captured_knowledge_ids.append(knowledge_id)
                
                logger.info(f"âœ… ã€çŸ¥è¯†æ•è·æˆåŠŸã€‘")
                logger.info(f"ğŸ“‹ çŸ¥è¯†ID: {knowledge_id}")
                logger.info(f"ğŸ·ï¸ çŸ¥è¯†ç±»å‹: {knowledge_type}")
                logger.info(f"ğŸ’¾ å­˜å‚¨è·¯å¾„: {result.get('file_path', 'N/A')}")
                
                # æ˜¾ç¤ºç»“æ„åŒ–çŸ¥è¯†ä¿¡æ¯
                structured_knowledge = result.get('structured_knowledge', {})
                if structured_knowledge:
                    logger.info(f"ğŸ“ æ ‡é¢˜: {structured_knowledge.get('title', 'N/A')}")
                    logger.info(f"ğŸ·ï¸ æ ‡ç­¾: {', '.join(structured_knowledge.get('tags', []))}")
                    logger.info(f"â­ é‡è¦æ€§: {structured_knowledge.get('importance', 0):.2f}")
                    logger.info(f"ğŸ”— å¯é æ€§: {structured_knowledge.get('metadata', {}).get('reliability', 0):.2f}")
            else:
                logger.error(f"âŒ ã€çŸ¥è¯†æ•è·å¤±è´¥ã€‘")
                logger.error(f"ğŸ’¥ é”™è¯¯ä¿¡æ¯: {result.get('error', 'N/A')}")
            
        except Exception as e:
            logger.error(f"âŒ çŸ¥è¯†æ•è·å¼‚å¸¸: {e}")
        
        await asyncio.sleep(0.5)
    
    # æµ‹è¯•å¤šç²’åº¦çŸ¥è¯†æ£€ç´¢åŠŸèƒ½
    logger.info("\nğŸ” å¼€å§‹å¤šç²’åº¦çŸ¥è¯†æ£€ç´¢æµ‹è¯•")
    
    query_test_cases = [
        {
            "name": "æ£€ç´¢å®Œæ•´ä»»åŠ¡çº§åˆ«çŸ¥è¯† - ç”µå•†è´­ç‰©æµç¨‹",
            "granularity": "complete_task",
            "task_context": {
                "task_type": "query",
                "query": "æ·˜å®è´­ç‰© ç”µå•†",
                "knowledge_type": "task_workflow",
                "tags": ["shopping", "complete_task", "e_commerce"],
                "limit": 5
            },
            "expected_features": ["workflow_steps", "complexity_level", "user_satisfaction"]
        },
        {
            "name": "æ£€ç´¢å­ä»»åŠ¡çº§åˆ«çŸ¥è¯† - ç‚¹å‡»æ“ä½œæŠ€å·§",
            "granularity": "subtask",
            "task_context": {
                "task_type": "query",
                "query": "ç‚¹å‡»æ“ä½œ click",
                "knowledge_type": "best_practice",
                "tags": ["click", "subtask", "mobile"],
                "limit": 5
            },
            "expected_features": ["subtask_type", "parent_task", "applicable_scenarios"]
        },
        {
            "name": "æ£€ç´¢åŸå­æ“ä½œçº§åˆ«çŸ¥è¯† - tapåæ ‡ä¼˜åŒ–",
            "granularity": "atomic_operation",
            "task_context": {
                "task_type": "query",
                "query": "tap åæ ‡ ä¼˜åŒ–",
                "knowledge_type": "action_pattern",
                "tags": ["tap", "atomic", "coordinates"],
                "limit": 5
            },
            "expected_features": ["operation_type", "parameters", "performance_metrics"]
        },
        {
            "name": "è·¨ç²’åº¦çŸ¥è¯†æ£€ç´¢ - ç‚¹å‡»ç›¸å…³çš„æ‰€æœ‰çŸ¥è¯†",
            "granularity": "cross_granularity",
            "task_context": {
                "task_type": "query",
                "query": "ç‚¹å‡» click tap",
                "limit": 10
            },
            "expected_granularities": ["complete_task", "subtask", "atomic_operation"]
        },
        {
            "name": "é¢†åŸŸç‰¹å®šçŸ¥è¯†æ£€ç´¢ - ç§»åŠ¨è‡ªåŠ¨åŒ–æœ€ä½³å®è·µ",
            "granularity": "domain_specific",
            "task_context": {
                "task_type": "query",
                "query": "mobile_automation",
                "tags": ["best_practice", "mobile"],
                "limit": 5
            },
            "expected_domains": ["mobile_automation", "e_commerce", "atomic_operations"]
        },
        {
            "name": "é”™è¯¯è§£å†³æ–¹æ¡ˆæ£€ç´¢",
            "granularity": "error_handling",
            "task_context": {
                "task_type": "query",
                "query": "error é”™è¯¯",
                "knowledge_type": "error_solution",
                "limit": 3
            },
            "expected_features": ["error_type", "solutions", "prevention"]
        }
    ]
    
    for i, query_case in enumerate(query_test_cases, 1):
        logger.info(f"\n{'='*50}")
        logger.info(f"å¤šç²’åº¦çŸ¥è¯†æ£€ç´¢ {i}: {query_case['name']}")
        logger.info(f"ğŸ¯ æµ‹è¯•ç²’åº¦: {query_case.get('granularity', 'N/A')}")
        logger.info(f"{'='*50}")
        
        try:
            result = await notetaker_agent._execute_task_impl(query_case['task_context'])
            
            if result.get('success', False):
                results = result.get('results', [])
                total_count = result.get('total_count', 0)
                returned_count = result.get('returned_count', 0)
                
                logger.info(f"ğŸ” ã€æ£€ç´¢æˆåŠŸã€‘")
                logger.info(f"ğŸ“Š æ€»è®¡æ‰¾åˆ°: {total_count}æ¡, è¿”å›: {returned_count}æ¡")
                logger.info(f"ğŸ” æŸ¥è¯¢æ¡ä»¶: {result.get('query', 'N/A')}")
                
                # éªŒè¯å¤šç²’åº¦çŸ¥è¯†ç‰¹å¾
                granularity_validation = await _validate_knowledge_granularity(
                    results, query_case
                )
                
                if granularity_validation['valid']:
                    logger.info(f"âœ… ã€ç²’åº¦éªŒè¯é€šè¿‡ã€‘: {granularity_validation['message']}")
                else:
                    logger.warning(f"âš ï¸ ã€ç²’åº¦éªŒè¯è­¦å‘Šã€‘: {granularity_validation['message']}")
                
                # æ˜¾ç¤ºæ£€ç´¢ç»“æœè¯¦æƒ…
                for j, knowledge_item in enumerate(results[:3], 1):  # åªæ˜¾ç¤ºå‰3æ¡
                    logger.info(f"\n  ğŸ“‹ ç»“æœ {j}:")
                    logger.info(f"     ğŸ·ï¸ ç±»å‹: [{knowledge_item.get('type', 'unknown')}]")
                    logger.info(f"     ğŸ“ æ ‡é¢˜: {knowledge_item.get('title', 'N/A')}")
                    logger.info(f"     ğŸŒ é¢†åŸŸ: {knowledge_item.get('domain', 'N/A')}")
                    logger.info(f"     ğŸ·ï¸ æ ‡ç­¾: {', '.join(knowledge_item.get('tags', []))}")
                    logger.info(f"     â­ é‡è¦æ€§: {knowledge_item.get('importance', 0):.2f}")
                    logger.info(f"     ğŸ“… åˆ›å»ºæ—¶é—´: {knowledge_item.get('created_at', 'N/A')}")
                    logger.info(f"     ğŸ”¢ è®¿é—®æ¬¡æ•°: {knowledge_item.get('access_count', 0)}")
                    
                    # æ˜¾ç¤ºå†…å®¹ç‰¹å¾ï¼ˆç”¨äºéªŒè¯ç²’åº¦ï¼‰
                    content = knowledge_item.get('content', {})
                    if isinstance(content, dict):
                        key_features = []
                        expected_features = query_case.get('expected_features', [])
                        for feature in expected_features:
                            if feature in content:
                                key_features.append(f"{feature}âœ“")
                            else:
                                key_features.append(f"{feature}âœ—")
                        if key_features:
                            logger.info(f"     ğŸ” ç‰¹å¾éªŒè¯: {', '.join(key_features)}")
                
                # ç»Ÿè®¡ä¸åŒç²’åº¦çš„çŸ¥è¯†åˆ†å¸ƒ
                granularity_stats = _analyze_granularity_distribution(results)
                if granularity_stats:
                    logger.info(f"\nğŸ“ˆ ç²’åº¦åˆ†å¸ƒç»Ÿè®¡:")
                    for granularity, count in granularity_stats.items():
                        logger.info(f"     {granularity}: {count}æ¡")
                        
            else:
                logger.error(f"âŒ ã€æ£€ç´¢å¤±è´¥ã€‘")
                logger.error(f"ğŸ’¥ é”™è¯¯ä¿¡æ¯: {result.get('error', 'N/A')}")
            
        except Exception as e:
            logger.error(f"âŒ çŸ¥è¯†æ£€ç´¢å¼‚å¸¸: {e}")
        
        await asyncio.sleep(0.5)
    
    # æµ‹è¯•çŸ¥è¯†ç»„ç»‡åŠŸèƒ½
    logger.info("\nğŸ—‚ï¸ å¼€å§‹çŸ¥è¯†ç»„ç»‡æµ‹è¯•")
    
    organization_test_cases = [
        {
            "name": "çŸ¥è¯†åˆ†ç±»æ•´ç†",
            "task_context": {
                "task_type": "organize",
                "organization_type": "categorize"
            }
        },
        {
            "name": "å…³è”çŸ¥è¯†é“¾æ¥",
            "task_context": {
                "task_type": "organize",
                "organization_type": "link"
            }
        },
        {
            "name": "ç”ŸæˆçŸ¥è¯†æ‘˜è¦",
            "task_context": {
                "task_type": "summary"
            }
        }
    ]
    
    for i, org_case in enumerate(organization_test_cases, 1):
        logger.info(f"\n{'='*50}")
        logger.info(f"çŸ¥è¯†ç»„ç»‡ {i}: {org_case['name']}")
        logger.info(f"{'='*50}")
        
        try:
            result = await notetaker_agent._execute_task_impl(org_case['task_context'])
            
            if result.get('success', False):
                logger.info(f"ğŸ—‚ï¸ ã€ç»„ç»‡æˆåŠŸã€‘")
                
                if 'categories' in result:
                    categories = result['categories']
                    logger.info(f"ğŸ“‚ åˆ†ç±»ç»“æœ: {len(categories)}ä¸ªç±»åˆ«")
                    for category, items in categories.items():
                        logger.info(f"  ğŸ“ {category}: {len(items)}é¡¹")
                
                if 'links_created' in result:
                    logger.info(f"ğŸ”— åˆ›å»ºé“¾æ¥: {result['links_created']}ä¸ª")
                
                if 'summary' in result:
                    summary = result['summary']
                    logger.info(f"ğŸ“Š çŸ¥è¯†åº“æ‘˜è¦:")
                    logger.info(f"  ğŸ“ æ€»è®¡é¡¹ç›®: {summary.get('total_items', 0)}")
                    
                    by_type = summary.get('by_type', {})
                    if by_type:
                        logger.info(f"  ğŸ“‚ æŒ‰ç±»å‹åˆ†å¸ƒ: {by_type}")
                    
                    by_importance = summary.get('by_importance', {})
                    if by_importance:
                        logger.info(f"  â­ æŒ‰é‡è¦æ€§åˆ†å¸ƒ: {by_importance}")
                    
                    recent_activity = summary.get('recent_activity', {})
                    if recent_activity:
                        logger.info(f"  ğŸ”„ æœ€è¿‘æ´»åŠ¨: æ•è·{recent_activity.get('recent_captures', 0)}æ¬¡, æŸ¥è¯¢{recent_activity.get('recent_queries', 0)}æ¬¡")
            else:
                logger.error(f"âŒ ã€ç»„ç»‡å¤±è´¥ã€‘")
                logger.error(f"ğŸ’¥ é”™è¯¯ä¿¡æ¯: {result.get('error', 'N/A')}")
            
        except Exception as e:
            logger.error(f"âŒ çŸ¥è¯†ç»„ç»‡å¼‚å¸¸: {e}")
        
        await asyncio.sleep(0.5)
    
    logger.info("\nğŸ‰ æ‰€æœ‰çŸ¥è¯†ç®¡ç†æµ‹è¯•å®Œæˆ")
    
    # æ˜¾ç¤ºçŸ¥è¯†ç®¡ç†ç»Ÿè®¡
    knowledge_stats = notetaker_agent.get_knowledge_stats()
    recent_captures = notetaker_agent.get_recent_captures()
    query_history = notetaker_agent.get_query_history()
    
    logger.info(f"\nğŸ“Š çŸ¥è¯†ç®¡ç†ç»Ÿè®¡:")
    logger.info(f"ğŸ“ æœ€è¿‘æ•è·: {len(recent_captures)}æ¬¡")
    logger.info(f"ğŸ” æŸ¥è¯¢å†å²: {len(query_history)}æ¬¡")
    
    if knowledge_stats:
        logger.info(f"ğŸ“ˆ çŸ¥è¯†åº“ç»Ÿè®¡: {knowledge_stats}")
    
    return notetaker_agent

async def test_knowledge_retrieval_capabilities(notetaker_agent: NotetakerAgent):
    """ä¸“é—¨æµ‹è¯•NotetakerAgentçš„çŸ¥è¯†æ£€ç´¢èƒ½åŠ›"""
    logger.info("\nğŸ¯ å¼€å§‹æµ‹è¯•NotetakerAgentçŸ¥è¯†æ£€ç´¢èƒ½åŠ›")
    
    retrieval_tests = [
        {
            "name": "åŸºç¡€æœç´¢èƒ½åŠ›æµ‹è¯•",
            "test_type": "basic_search",
            "queries": [
                {"query": "click", "expected_min": 1},
                {"query": "tap", "expected_min": 1},
                {"query": "è´­ç‰©", "expected_min": 1},
                {"query": "error", "expected_min": 1}
            ]
        },
        {
            "name": "ç±»å‹ç‰¹å®šæ£€ç´¢æµ‹è¯•",
            "test_type": "type_specific",
            "queries": [
                {"area": "mobile_automation", "method": "get_best_practices"},
                {"area": "click_operations", "method": "get_best_practices"},
                {"error_type": "element_not_found", "method": "get_error_solutions"},
                {"error_type": None, "method": "get_error_solutions"}
            ]
        },
        {
            "name": "å¤šç²’åº¦æ£€ç´¢éªŒè¯",
            "test_type": "multi_granularity",
            "queries": [
                {"query": "æ·˜å®è´­ç‰©", "expected_granularity": "complete_task"},
                {"query": "ç‚¹å‡»æ“ä½œ", "expected_granularity": "subtask"},
                {"query": "tapåæ ‡", "expected_granularity": "atomic_operation"}
            ]
        },
        {
            "name": "è¯­ä¹‰ç†è§£æ£€ç´¢æµ‹è¯•",
            "test_type": "semantic_search",
            "queries": [
                {"query": "å¦‚ä½•ç‚¹å‡»æŒ‰é’®", "expected_concepts": ["click", "button", "tap"]},
                {"query": "è´­ä¹°å•†å“æµç¨‹", "expected_concepts": ["shopping", "workflow", "e_commerce"]},
                {"query": "æ“ä½œå¤±è´¥æ€ä¹ˆåŠ", "expected_concepts": ["error", "solution", "recovery"]}
            ]
        }
    ]
    
    total_tests = 0
    passed_tests = 0
    
    for test_group in retrieval_tests:
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ§ª {test_group['name']}")
        logger.info(f"{'='*60}")
        
        for i, query_test in enumerate(test_group['queries'], 1):
            total_tests += 1
            test_passed = False
            
            try:
                if test_group['test_type'] == 'basic_search':
                    # åŸºç¡€æœç´¢æµ‹è¯•
                    query = query_test['query']
                    expected_min = query_test['expected_min']
                    
                    results = await notetaker_agent.search_knowledge(query, limit=5)
                    
                    if len(results) >= expected_min:
                        logger.info(f"âœ… åŸºç¡€æœç´¢ {i}: '{query}' -> æ‰¾åˆ°{len(results)}æ¡ç»“æœ (â‰¥{expected_min})")
                        test_passed = True
                    else:
                        logger.warning(f"âš ï¸ åŸºç¡€æœç´¢ {i}: '{query}' -> ä»…æ‰¾åˆ°{len(results)}æ¡ç»“æœ (<{expected_min})")
                
                elif test_group['test_type'] == 'type_specific':
                    # ç±»å‹ç‰¹å®šæ£€ç´¢æµ‹è¯•
                    method = query_test['method']
                    
                    if method == 'get_best_practices':
                        area = query_test.get('area')
                        results = await notetaker_agent.get_best_practices(area)
                        logger.info(f"âœ… æœ€ä½³å®è·µæ£€ç´¢ {i}: é¢†åŸŸ'{area}' -> æ‰¾åˆ°{len(results)}æ¡")
                        test_passed = True
                    
                    elif method == 'get_error_solutions':
                        error_type = query_test.get('error_type')
                        results = await notetaker_agent.get_error_solutions(error_type)
                        logger.info(f"âœ… é”™è¯¯è§£å†³æ–¹æ¡ˆæ£€ç´¢ {i}: ç±»å‹'{error_type}' -> æ‰¾åˆ°{len(results)}æ¡")
                        test_passed = True
                
                elif test_group['test_type'] == 'multi_granularity':
                    # å¤šç²’åº¦æ£€ç´¢éªŒè¯
                    query = query_test['query']
                    expected_granularity = query_test['expected_granularity']
                    
                    results = await notetaker_agent.search_knowledge(query, limit=5)
                    
                    # æ£€æŸ¥ç»“æœä¸­æ˜¯å¦åŒ…å«é¢„æœŸç²’åº¦çš„çŸ¥è¯†
                    granularity_found = False
                    for result in results:
                        tags = result.get('tags', [])
                        knowledge_type = result.get('type', '')
                        
                        if expected_granularity == 'complete_task' and ('complete_task' in tags or knowledge_type == 'task_workflow'):
                            granularity_found = True
                            break
                        elif expected_granularity == 'subtask' and ('subtask' in tags or knowledge_type == 'best_practice'):
                            granularity_found = True
                            break
                        elif expected_granularity == 'atomic_operation' and ('atomic' in tags or knowledge_type == 'action_pattern'):
                            granularity_found = True
                            break
                    
                    if granularity_found:
                        logger.info(f"âœ… å¤šç²’åº¦æ£€ç´¢ {i}: '{query}' -> æ‰¾åˆ°{expected_granularity}çº§åˆ«çŸ¥è¯†")
                        test_passed = True
                    else:
                        logger.warning(f"âš ï¸ å¤šç²’åº¦æ£€ç´¢ {i}: '{query}' -> æœªæ‰¾åˆ°{expected_granularity}çº§åˆ«çŸ¥è¯†")
                
                elif test_group['test_type'] == 'semantic_search':
                    # è¯­ä¹‰ç†è§£æ£€ç´¢æµ‹è¯•
                    query = query_test['query']
                    expected_concepts = query_test['expected_concepts']
                    
                    results = await notetaker_agent.search_knowledge(query, limit=5)
                    
                    # æ£€æŸ¥ç»“æœä¸­æ˜¯å¦åŒ…å«é¢„æœŸæ¦‚å¿µ
                    concepts_found = 0
                    for result in results:
                        content_str = str(result.get('content', '')).lower()
                        title_str = str(result.get('title', '')).lower()
                        tags_str = ' '.join(result.get('tags', [])).lower()
                        
                        full_text = f"{content_str} {title_str} {tags_str}"
                        
                        for concept in expected_concepts:
                            if concept.lower() in full_text:
                                concepts_found += 1
                                break
                    
                    concept_coverage = concepts_found / len(results) if results else 0
                    
                    if concept_coverage >= 0.3:  # è‡³å°‘30%çš„ç»“æœåŒ…å«é¢„æœŸæ¦‚å¿µ
                        logger.info(f"âœ… è¯­ä¹‰æ£€ç´¢ {i}: '{query}' -> æ¦‚å¿µè¦†ç›–ç‡{concept_coverage:.1%}")
                        test_passed = True
                    else:
                        logger.warning(f"âš ï¸ è¯­ä¹‰æ£€ç´¢ {i}: '{query}' -> æ¦‚å¿µè¦†ç›–ç‡ä»…{concept_coverage:.1%}")
                
                if test_passed:
                    passed_tests += 1
                    
            except Exception as e:
                logger.error(f"âŒ æ£€ç´¢æµ‹è¯• {i} å¼‚å¸¸: {e}")
            
            await asyncio.sleep(0.2)
    
    # è¾“å‡ºæµ‹è¯•æ€»ç»“
    success_rate = passed_tests / total_tests if total_tests > 0 else 0
    logger.info(f"\nğŸ“Š çŸ¥è¯†æ£€ç´¢èƒ½åŠ›æµ‹è¯•æ€»ç»“:")
    logger.info(f"   æ€»æµ‹è¯•æ•°: {total_tests}")
    logger.info(f"   é€šè¿‡æµ‹è¯•: {passed_tests}")
    logger.info(f"   æˆåŠŸç‡: {success_rate:.1%}")
    
    if success_rate >= 0.8:
        logger.info(f"ğŸ‰ NotetakerAgentçŸ¥è¯†æ£€ç´¢èƒ½åŠ›æµ‹è¯• - ä¼˜ç§€ï¼")
    elif success_rate >= 0.6:
        logger.info(f"ğŸ‘ NotetakerAgentçŸ¥è¯†æ£€ç´¢èƒ½åŠ›æµ‹è¯• - è‰¯å¥½")
    else:
        logger.warning(f"âš ï¸ NotetakerAgentçŸ¥è¯†æ£€ç´¢èƒ½åŠ›éœ€è¦æ”¹è¿›")
    
    return {
        'total_tests': total_tests,
        'passed_tests': passed_tests,
        'success_rate': success_rate
    }


async def test_convenience_methods():
    """æµ‹è¯•ä¾¿æ·æ–¹æ³•"""
    logger.info("\nğŸ› ï¸ å¼€å§‹æµ‹è¯•ä¾¿æ·æ–¹æ³•")
    
    # åˆå§‹åŒ–NotetakerAgent
    api_key = os.getenv('BAILIAN_API_KEY')
    if api_key:
        llm_provider = BailianProvider(
            api_key=api_key,
            model="qwen-vl-max",
            temperature=0.3
        )
        
        notetaker_agent = NotetakerAgent(
            llm_provider=llm_provider,
            agent_id="convenience_test_notetaker"
        )
        
        # æµ‹è¯•æœç´¢çŸ¥è¯†
        logger.info("ğŸ” æµ‹è¯•æœç´¢çŸ¥è¯†åŠŸèƒ½")
        try:
            search_results = await notetaker_agent.search_knowledge("click", limit=3)
            logger.info(f"æœç´¢ç»“æœ: æ‰¾åˆ°{len(search_results)}æ¡ç›¸å…³çŸ¥è¯†")
            for i, item in enumerate(search_results, 1):
                logger.info(f"  {i}. {item.get('title', 'N/A')}")
        except Exception as e:
            logger.error(f"æœç´¢çŸ¥è¯†å¤±è´¥: {e}")
        
        # æµ‹è¯•è·å–æœ€ä½³å®è·µ
        logger.info("\nğŸ’¡ æµ‹è¯•è·å–æœ€ä½³å®è·µ")
        try:
            best_practices = await notetaker_agent.get_best_practices("mobile_automation")
            logger.info(f"æœ€ä½³å®è·µ: æ‰¾åˆ°{len(best_practices)}æ¡")
            for i, practice in enumerate(best_practices, 1):
                logger.info(f"  {i}. {practice.get('title', 'N/A')}")
        except Exception as e:
            logger.error(f"è·å–æœ€ä½³å®è·µå¤±è´¥: {e}")
        
        # æµ‹è¯•è·å–é”™è¯¯è§£å†³æ–¹æ¡ˆ
        logger.info("\nğŸ”§ æµ‹è¯•è·å–é”™è¯¯è§£å†³æ–¹æ¡ˆ")
        try:
            error_solutions = await notetaker_agent.get_error_solutions("element_not_found")
            logger.info(f"é”™è¯¯è§£å†³æ–¹æ¡ˆ: æ‰¾åˆ°{len(error_solutions)}æ¡")
            for i, solution in enumerate(error_solutions, 1):
                logger.info(f"  {i}. {solution.get('title', 'N/A')}")
        except Exception as e:
            logger.error(f"è·å–é”™è¯¯è§£å†³æ–¹æ¡ˆå¤±è´¥: {e}")
        
        # è¿è¡ŒçŸ¥è¯†æ£€ç´¢èƒ½åŠ›æµ‹è¯•
        await test_knowledge_retrieval_capabilities(notetaker_agent)
        
    else:
        logger.warning("æœªè®¾ç½®BAILIAN_API_KEYï¼Œè·³è¿‡ä¾¿æ·æ–¹æ³•æµ‹è¯•")

def main():
    """ä¸»å‡½æ•°"""
    try:
        # è¿è¡ŒåŸºç¡€æµ‹è¯•
        notetaker_agent = asyncio.run(test_multimodal_knowledge_management())
        
        # è¿è¡Œä¾¿æ·æ–¹æ³•æµ‹è¯•
        asyncio.run(test_convenience_methods())
        
        logger.info("\nğŸŠ æ‰€æœ‰çŸ¥è¯†ç®¡ç†æµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        logger.error("\nğŸ’¡ è¯·æ£€æŸ¥:")
        logger.error("   1. æ˜¯å¦åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®äº† BAILIAN_API_KEY")
        logger.error("   2. API Keyæ˜¯å¦æœ‰æ•ˆä¸”æœ‰è¶³å¤Ÿé¢åº¦")
        logger.error("   3. ç½‘ç»œè¿æ¥æ˜¯å¦å¯ä»¥è®¿é—®ç™¾ç‚¼APIæœåŠ¡")
        logger.error("   4. æ˜¯å¦å·²å®‰è£…æ‰€éœ€ä¾èµ–")
        logger.error("   5. knowledge_baseç›®å½•æ˜¯å¦å¯å†™")

if __name__ == "__main__":
    main()