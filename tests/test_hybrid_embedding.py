#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Hybrid Embedding Performance Test
æ··åˆembeddingæ€§èƒ½æµ‹è¯•å’Œè°ƒä¼˜å·¥å…·

Author: AgenticX Team
Date: 2025
"""

import asyncio
import time
import json
import os
import sys
from pathlib import Path
from typing import Dict, Any, List
from dataclasses import asdict

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from knowledge.embedding_config import (
    EmbeddingStrategy, EmbeddingRequest, ContentType, EmbeddingType, EmbeddingConfig
)
from knowledge.embedding_factory import EmbeddingFactory
from knowledge.config_loader import load_embedding_config, validate_config
from utils import setup_logger, get_iso_timestamp

# åŠ è½½ç¯å¢ƒå˜é‡
from dotenv import load_dotenv
# æ˜ç¡®æŒ‡å®š.envæ–‡ä»¶è·¯å¾„
env_path = Path(__file__).parent / '.env'
load_dotenv(env_path)


class EmbeddingPerformanceTester:
    """Embeddingæ€§èƒ½æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.logger = logger
        self.test_results = []
        self.hybrid_manager = None
    
    async def setup(self) -> bool:
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        try:
            # éªŒè¯é…ç½®
            if not validate_config():
                logger.error("Embeddingé…ç½®éªŒè¯å¤±è´¥")
                return False
            
            # åŠ è½½é…ç½®
            embedding_config = load_embedding_config()
            
            # åˆ›å»ºæ··åˆç®¡ç†å™¨
            self.hybrid_manager = EmbeddingFactory.create_hybrid_from_config(embedding_config)
            
            logger.info("æµ‹è¯•ç¯å¢ƒè®¾ç½®æˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"æµ‹è¯•ç¯å¢ƒè®¾ç½®å¤±è´¥: {e}")
            return False
    
    async def test_text_embedding_performance(self) -> Dict[str, Any]:
        """æµ‹è¯•æ–‡æœ¬embeddingæ€§èƒ½"""
        logger.info("å¼€å§‹æ–‡æœ¬embeddingæ€§èƒ½æµ‹è¯•")
        
        test_cases = [
            "ç®€å•çš„æ–‡æœ¬å†…å®¹",
            "è¿™æ˜¯ä¸€ä¸ªåŒ…å«æ›´å¤šä¿¡æ¯çš„è¾ƒé•¿æ–‡æœ¬ï¼Œç”¨äºæµ‹è¯•embeddingçš„å¤„ç†èƒ½åŠ›å’Œæ€§èƒ½è¡¨ç°ã€‚",
            "GUIæ“ä½œï¼šç‚¹å‡»ç™»å½•æŒ‰é’®ï¼Œè¾“å…¥ç”¨æˆ·åå’Œå¯†ç ï¼Œç„¶åç‚¹å‡»ç¡®è®¤æŒ‰é’®å®Œæˆç™»å½•æµç¨‹ã€‚",
            "ç§»åŠ¨åº”ç”¨ç•Œé¢åˆ†æï¼šå½“å‰å±å¹•æ˜¾ç¤ºä¸»é¡µé¢ï¼ŒåŒ…å«å¯¼èˆªæ ã€æœç´¢æ¡†ã€æ¨èå†…å®¹åˆ—è¡¨ç­‰UIå…ƒç´ ã€‚"
        ]
        
        results = []
        
        for i, text in enumerate(test_cases):
            start_time = time.time()
            
            try:
                request = EmbeddingRequest(
                    content=text,
                    content_type=ContentType.PURE_TEXT,
                    priority="normal"
                )
                
                result = await self.hybrid_manager.embed(request)
                
                processing_time = time.time() - start_time
                
                test_result = {
                    'test_case': f'text_{i+1}',
                    'content_length': len(text),
                    'embedding_type': result.embedding_type.value,
                    'processing_time': processing_time,
                    'cache_hit': result.cache_hit,
                    'cost_estimate': result.cost_estimate,
                    'embedding_dimension': len(result.embeddings[0]) if result.embeddings else 0,
                    'success': True
                }
                
                results.append(test_result)
                logger.info(f"æ–‡æœ¬æµ‹è¯• {i+1}: {processing_time:.3f}s, ç¼“å­˜å‘½ä¸­: {result.cache_hit}")
                
            except Exception as e:
                logger.error(f"æ–‡æœ¬æµ‹è¯• {i+1} å¤±è´¥: {e}")
                results.append({
                    'test_case': f'text_{i+1}',
                    'success': False,
                    'error': str(e)
                })
        
        return {
            'test_type': 'text_embedding',
            'total_cases': len(test_cases),
            'results': results,
            'avg_processing_time': sum(r.get('processing_time', 0) for r in results) / len(results),
            'cache_hit_rate': sum(1 for r in results if r.get('cache_hit', False)) / len(results)
        }
    
    async def test_multimodal_embedding_performance(self) -> Dict[str, Any]:
        """æµ‹è¯•å¤šæ¨¡æ€embeddingæ€§èƒ½"""
        logger.info("å¼€å§‹å¤šæ¨¡æ€embeddingæ€§èƒ½æµ‹è¯•")
        
        test_cases = [
            # çº¯æ–‡æœ¬ï¼ˆåº”è¯¥è¢«æ™ºèƒ½è·¯ç”±åˆ°æ–‡æœ¬embeddingï¼‰
            [{'text': 'çº¯æ–‡æœ¬å†…å®¹æµ‹è¯•'}],
            
            # æ–‡æœ¬+å›¾ç‰‡
            [
                {'text': 'ç™»å½•é¡µé¢æˆªå›¾'},
                {'image': 'https://i.imgur.com/CzXTtJV.jpg'}  # çœŸå®å¯è®¿é—®çš„æµ‹è¯•å›¾ç‰‡
            ],
            
            # å¤šä¸ªæ–‡æœ¬å’Œå›¾ç‰‡
            [
                {'text': 'ç§»åŠ¨åº”ç”¨ä¸»ç•Œé¢'},
                {'image': 'https://farm4.staticflickr.com/3075/3168662394_7d7103de7d_z_d.jpg'},  # çœŸå®å¯è®¿é—®çš„æµ‹è¯•å›¾ç‰‡
                {'text': 'åŒ…å«å¯¼èˆªæ ã€æœç´¢æ¡†ç­‰UIå…ƒç´ '},
                {'image': 'https://farm9.staticflickr.com/8295/8007075227_dc958c1fe6_z_d.jpg'}  # çœŸå®å¯è®¿é—®çš„æµ‹è¯•å›¾ç‰‡
            ],
            
            # å¤æ‚å¤šæ¨¡æ€å†…å®¹
            [
                {'text': 'GUIè‡ªåŠ¨åŒ–æµ‹è¯•åœºæ™¯'},
                {'image': 'https://farm2.staticflickr.com/1449/24800673529_64272a66ec_z_d.jpg'},  # çœŸå®å¯è®¿é—®çš„æµ‹è¯•å›¾ç‰‡
                {'text': 'æ“ä½œæ­¥éª¤ï¼š1. æ‰“å¼€åº”ç”¨ 2. ç‚¹å‡»æŒ‰é’® 3. éªŒè¯ç»“æœ'},
                {'image': 'https://farm4.staticflickr.com/3827/11349066413_99c32dee4a_z_d.jpg'}  # çœŸå®å¯è®¿é—®çš„æµ‹è¯•å›¾ç‰‡
            ]
        ]
        
        results = []
        
        for i, content in enumerate(test_cases):
            start_time = time.time()
            
            try:
                request = EmbeddingRequest(
                    content=content,
                    content_type=ContentType.AUTO,  # è‡ªåŠ¨æ£€æµ‹
                    priority="normal"
                )
                
                result = await self.hybrid_manager.embed(request)
                
                processing_time = time.time() - start_time
                
                test_result = {
                    'test_case': f'multimodal_{i+1}',
                    'content_items': len(content),
                    'embedding_type': result.embedding_type.value,
                    'processing_time': processing_time,
                    'cache_hit': result.cache_hit,
                    'cost_estimate': result.cost_estimate,
                    'embedding_dimension': len(result.embeddings[0]) if result.embeddings else 0,
                    'success': True
                }
                
                results.append(test_result)
                logger.info(f"å¤šæ¨¡æ€æµ‹è¯• {i+1}: {processing_time:.3f}s, ç±»å‹: {result.embedding_type.value}")
                
            except Exception as e:
                logger.error(f"å¤šæ¨¡æ€æµ‹è¯• {i+1} å¤±è´¥: {e}")
                results.append({
                    'test_case': f'multimodal_{i+1}',
                    'success': False,
                    'error': str(e)
                })
        
        return {
            'test_type': 'multimodal_embedding',
            'total_cases': len(test_cases),
            'results': results,
            'avg_processing_time': sum(r.get('processing_time', 0) for r in results) / len(results),
            'text_routing_rate': sum(1 for r in results if r.get('embedding_type') == 'text') / len(results),
            'multimodal_routing_rate': sum(1 for r in results if r.get('embedding_type') == 'multimodal') / len(results)
        }
    
    async def test_cache_performance(self) -> Dict[str, Any]:
        """æµ‹è¯•ç¼“å­˜æ€§èƒ½"""
        logger.info("å¼€å§‹ç¼“å­˜æ€§èƒ½æµ‹è¯•")
        
        # æµ‹è¯•å†…å®¹
        test_content = "GUIæ“ä½œæµ‹è¯•ï¼šç‚¹å‡»æŒ‰é’®ï¼ŒéªŒè¯å“åº”"
        
        # ç¬¬ä¸€æ¬¡è¯·æ±‚ï¼ˆåº”è¯¥ç¼“å­˜missï¼‰
        start_time = time.time()
        request = EmbeddingRequest(
            content=test_content,
            content_type=ContentType.PURE_TEXT
        )
        
        first_result = await self.hybrid_manager.embed(request)
        first_time = time.time() - start_time
        
        # ç¬¬äºŒæ¬¡è¯·æ±‚ï¼ˆåº”è¯¥ç¼“å­˜hitï¼‰
        start_time = time.time()
        second_result = await self.hybrid_manager.embed(request)
        second_time = time.time() - start_time
        
        # æ‰¹é‡æµ‹è¯•ç¼“å­˜æ€§èƒ½
        batch_times = []
        for i in range(10):
            start_time = time.time()
            await self.hybrid_manager.embed(request)
            batch_times.append(time.time() - start_time)
        
        return {
            'test_type': 'cache_performance',
            'first_request': {
                'time': first_time,
                'cache_hit': first_result.cache_hit
            },
            'second_request': {
                'time': second_time,
                'cache_hit': second_result.cache_hit
            },
            'speedup_ratio': first_time / second_time if second_time > 0 else 0,
            'batch_avg_time': sum(batch_times) / len(batch_times),
            'cache_stats': self.hybrid_manager.get_stats()['cache_stats']
        }
    
    async def test_cost_optimization(self) -> Dict[str, Any]:
        """æµ‹è¯•æˆæœ¬ä¼˜åŒ–"""
        logger.info("å¼€å§‹æˆæœ¬ä¼˜åŒ–æµ‹è¯•")
        
        # æµ‹è¯•ä¸åŒç­–ç•¥çš„æˆæœ¬
        strategies = [
            EmbeddingStrategy(
                cost_threshold_multimodal=0.1,  # ä½é˜ˆå€¼ï¼Œåå‘æ–‡æœ¬
                prefer_multimodal_for_gui=False
            ),
            EmbeddingStrategy(
                cost_threshold_multimodal=1.0,  # é«˜é˜ˆå€¼ï¼Œåå‘å¤šæ¨¡æ€
                prefer_multimodal_for_gui=True
            )
        ]
        
        test_content = [
            {'text': 'GUIæ“ä½œæè¿°'},
            {'image': 'https://i.imgur.com/OnwEDW3.jpg'}  # çœŸå®å¯è®¿é—®çš„æµ‹è¯•å›¾ç‰‡
        ]
        
        results = []
        
        for i, strategy in enumerate(strategies):
            # æ›´æ–°ç­–ç•¥
            self.hybrid_manager.update_strategy(strategy)
            
            start_time = time.time()
            request = EmbeddingRequest(
                content=test_content,
                content_type=ContentType.AUTO
            )
            
            result = await self.hybrid_manager.embed(request)
            processing_time = time.time() - start_time
            
            results.append({
                'strategy': f'strategy_{i+1}',
                'embedding_type': result.embedding_type.value,
                'processing_time': processing_time,
                'cost_estimate': result.cost_estimate,
                'threshold': strategy.cost_threshold_multimodal
            })
        
        return {
            'test_type': 'cost_optimization',
            'results': results,
            'cost_difference': abs(results[0]['cost_estimate'] - results[1]['cost_estimate']) if len(results) == 2 else 0
        }
    
    async def test_batch_processing(self) -> Dict[str, Any]:
        """æµ‹è¯•æ‰¹é‡å¤„ç†æ€§èƒ½"""
        logger.info("å¼€å§‹æ‰¹é‡å¤„ç†æ€§èƒ½æµ‹è¯•")
        
        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        batch_sizes = [1, 5, 10, 20, 50]
        results = []
        
        for batch_size in batch_sizes:
            # ç”Ÿæˆæ‰¹é‡æ–‡æœ¬
            texts = [f"æµ‹è¯•æ–‡æœ¬ {i+1}: GUIæ“ä½œæè¿°" for i in range(batch_size)]
            
            start_time = time.time()
            
            # å¹¶å‘å¤„ç†
            tasks = []
            for text in texts:
                request = EmbeddingRequest(
                    content=text,
                    content_type=ContentType.PURE_TEXT
                )
                tasks.append(self.hybrid_manager.embed(request))
            
            batch_results = await asyncio.gather(*tasks, return_exceptions=True)
            processing_time = time.time() - start_time
            
            # ç»Ÿè®¡æˆåŠŸç‡
            success_count = sum(1 for r in batch_results if not isinstance(r, Exception))
            
            results.append({
                'batch_size': batch_size,
                'processing_time': processing_time,
                'avg_time_per_item': processing_time / batch_size,
                'success_rate': success_count / batch_size,
                'throughput': batch_size / processing_time if processing_time > 0 else 0
            })
            
            logger.info(f"æ‰¹é‡æµ‹è¯• {batch_size}: {processing_time:.3f}s, ååé‡: {results[-1]['throughput']:.2f} items/s")
        
        return {
            'test_type': 'batch_processing',
            'results': results,
            'optimal_batch_size': max(results, key=lambda x: x['throughput'])['batch_size']
        }
    
    async def run_comprehensive_test(self) -> Dict[str, Any]:
        """è¿è¡Œç»¼åˆæ€§èƒ½æµ‹è¯•"""
        logger.info("å¼€å§‹ç»¼åˆæ€§èƒ½æµ‹è¯•")
        
        if not await self.setup():
            return {'error': 'æµ‹è¯•ç¯å¢ƒè®¾ç½®å¤±è´¥'}
        
        test_results = {
            'test_timestamp': get_iso_timestamp(),
            'test_environment': {
                'python_version': sys.version,
                'embedding_config': load_embedding_config()
            }
        }
        
        try:
            # è¿è¡Œå„é¡¹æµ‹è¯•
            test_results['text_embedding'] = await self.test_text_embedding_performance()
            test_results['multimodal_embedding'] = await self.test_multimodal_embedding_performance()
            test_results['cache_performance'] = await self.test_cache_performance()
            test_results['cost_optimization'] = await self.test_cost_optimization()
            test_results['batch_processing'] = await self.test_batch_processing()
            
            # è·å–æœ€ç»ˆç»Ÿè®¡
            test_results['final_stats'] = self.hybrid_manager.get_stats()
            
            # ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
            test_results['performance_summary'] = self._generate_performance_summary(test_results)
            
        except Exception as e:
            logger.error(f"æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
            test_results['error'] = str(e)
        
        finally:
            # æ¸…ç†èµ„æº
            if self.hybrid_manager:
                await self.hybrid_manager.close()
        
        return test_results
    
    def _generate_performance_summary(self, test_results: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆæ€§èƒ½æ‘˜è¦"""
        summary = {
            'overall_performance': 'good',
            'recommendations': [],
            'key_metrics': {}
        }
        
        try:
            # åˆ†ææ–‡æœ¬embeddingæ€§èƒ½
            text_results = test_results.get('text_embedding', {})
            if text_results:
                avg_time = text_results.get('avg_processing_time', 0)
                summary['key_metrics']['text_avg_time'] = avg_time
                
                if avg_time > 1.0:
                    summary['recommendations'].append('æ–‡æœ¬embeddingå¤„ç†æ—¶é—´è¾ƒé•¿ï¼Œå»ºè®®ä¼˜åŒ–æ‰¹é‡å¤§å°æˆ–å¯ç”¨ç¼“å­˜')
            
            # åˆ†æç¼“å­˜æ€§èƒ½
            cache_results = test_results.get('cache_performance', {})
            if cache_results:
                speedup = cache_results.get('speedup_ratio', 0)
                summary['key_metrics']['cache_speedup'] = speedup
                
                if speedup < 5:
                    summary['recommendations'].append('ç¼“å­˜åŠ é€Ÿæ•ˆæœä¸æ˜æ˜¾ï¼Œå»ºè®®æ£€æŸ¥ç¼“å­˜é…ç½®')
            
            # åˆ†ææ‰¹é‡å¤„ç†æ€§èƒ½
            batch_results = test_results.get('batch_processing', {})
            if batch_results:
                optimal_batch = batch_results.get('optimal_batch_size', 0)
                summary['key_metrics']['optimal_batch_size'] = optimal_batch
                
                if optimal_batch < 10:
                    summary['recommendations'].append('å»ºè®®å¢åŠ æ‰¹é‡å¤„ç†å¤§å°ä»¥æé«˜ååé‡')
            
            # åˆ†ææˆæœ¬ä¼˜åŒ–
            cost_results = test_results.get('cost_optimization', {})
            if cost_results:
                cost_diff = cost_results.get('cost_difference', 0)
                summary['key_metrics']['cost_optimization_potential'] = cost_diff
                
                if cost_diff > 0.1:
                    summary['recommendations'].append('ä¸åŒç­–ç•¥é—´æˆæœ¬å·®å¼‚è¾ƒå¤§ï¼Œå»ºè®®æ ¹æ®ä½¿ç”¨åœºæ™¯è°ƒæ•´ç­–ç•¥')
            
            # ç»¼åˆè¯„ä¼°
            if len(summary['recommendations']) == 0:
                summary['overall_performance'] = 'excellent'
            elif len(summary['recommendations']) <= 2:
                summary['overall_performance'] = 'good'
            else:
                summary['overall_performance'] = 'needs_improvement'
        
        except Exception as e:
            summary['error'] = f'æ€§èƒ½æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}'
        
        return summary
    
    def save_results(self, results: Dict[str, Any], filename: str = None) -> str:
        """ä¿å­˜æµ‹è¯•ç»“æœ"""
        if filename is None:
            timestamp = get_iso_timestamp().replace(':', '-').replace('.', '-')
            filename = f'embedding_performance_test_{timestamp}.json'
        
        results_dir = Path(__file__).parent / 'results'
        results_dir.mkdir(exist_ok=True)
        
        filepath = results_dir / filename
        
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
            
            logger.info(f"æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {filepath}")
            return str(filepath)
            
        except Exception as e:
            logger.error(f"ä¿å­˜æµ‹è¯•ç»“æœå¤±è´¥: {e}")
            return ""


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ AgenticX-GUIAgent æ··åˆEmbeddingæ€§èƒ½æµ‹è¯•")
    print("=" * 50)
    
    tester = EmbeddingPerformanceTester()
    
    # è¿è¡Œç»¼åˆæµ‹è¯•
    results = await tester.run_comprehensive_test()
    
    # ä¿å­˜ç»“æœ
    filepath = tester.save_results(results)
    
    # æ‰“å°æ‘˜è¦
    if 'performance_summary' in results:
        summary = results['performance_summary']
        print(f"\nğŸ“Š æ€§èƒ½æµ‹è¯•æ‘˜è¦:")
        print(f"æ€»ä½“æ€§èƒ½: {summary.get('overall_performance', 'unknown')}")
        
        if 'key_metrics' in summary:
            print(f"\nğŸ”‘ å…³é”®æŒ‡æ ‡:")
            for metric, value in summary['key_metrics'].items():
                print(f"  - {metric}: {value}")
        
        if 'recommendations' in summary and summary['recommendations']:
            print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
            for i, rec in enumerate(summary['recommendations'], 1):
                print(f"  {i}. {rec}")
    
    if 'error' in results:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {results['error']}")
    else:
        print(f"\nâœ… æµ‹è¯•å®Œæˆï¼Œç»“æœå·²ä¿å­˜åˆ°: {filepath}")
    
    print("\n" + "=" * 50)


if __name__ == "__main__":
    asyncio.run(main())