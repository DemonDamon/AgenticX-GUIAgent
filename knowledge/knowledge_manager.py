#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AgenticX-GUIAgent Knowledge Manager
åŸºäºAgenticXæ¡†æ¶çš„çŸ¥è¯†ç®¡ç†å™¨ï¼šä½¿ç”¨AgenticXçš„storageå’Œretrievalç»„ä»¶

é‡æ„è¯´æ˜ï¼š
- ä½¿ç”¨AgenticXçš„StorageManagerå’Œæ£€ç´¢ç»„ä»¶
- é›†æˆAgenticXçš„äº‹ä»¶ç³»ç»Ÿè¿›è¡ŒçŸ¥è¯†ç®¡ç†
- æä¾›ç°ä»£åŒ–çš„çŸ¥è¯†ç”Ÿå‘½å‘¨æœŸç®¡ç†
- ç§»é™¤é‡å¤çš„è‡ªå®šä¹‰å®ç°

Author: AgenticX Team
Date: 2025
"""

import asyncio
import json
import threading
from collections import defaultdict, deque
from datetime import datetime, timedelta, UTC
from typing import (
    Any, Dict, List, Optional, Set, Tuple, Union,
    Callable, Awaitable
)
from uuid import uuid4
from loguru import logger

from .knowledge_types import (
    KnowledgeItem, KnowledgeType, KnowledgeSource, KnowledgeStatus,
    KnowledgeRelation, RelationType, QueryRequest, QueryResult,
    SyncRequest, SyncResult, KnowledgeMetadata
)
# ä½¿ç”¨AgenticXæ ¸å¿ƒç»„ä»¶
from agenticx.core.component import Component
from agenticx.core.event import Event
from agenticx.core.event_bus import EventBus
from agenticx.memory.component import MemoryComponent

# ä½¿ç”¨AgenticXå­˜å‚¨å’Œæ£€ç´¢ç»„ä»¶
from .agenticx_adapter import AgenticXKnowledgeManager, AgenticXConfig, MockEmbeddingProvider
from .knowledge_store import KnowledgeStoreInterface, KnowledgeStoreFactory
from utils import get_iso_timestamp, setup_logger


class KnowledgeCache:
    """çŸ¥è¯†ç¼“å­˜"""
    
    def __init__(self, max_size: int = 1000, ttl_seconds: int = 3600):
        self.max_size = max_size
        self.ttl_seconds = ttl_seconds
        self._cache: Dict[str, Tuple[KnowledgeItem, datetime]] = {}
        self._access_order = deque()
        self._lock = threading.RLock()
    
    def get(self, knowledge_id: str) -> Optional[KnowledgeItem]:
        """è·å–ç¼“å­˜çš„çŸ¥è¯†"""
        with self._lock:
            if knowledge_id in self._cache:
                knowledge, cached_time = self._cache[knowledge_id]
                
                # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
                if datetime.now() - cached_time > timedelta(seconds=self.ttl_seconds):
                    self._remove(knowledge_id)
                    return None
                
                # æ›´æ–°è®¿é—®é¡ºåº
                if knowledge_id in self._access_order:
                    self._access_order.remove(knowledge_id)
                self._access_order.append(knowledge_id)
                
                return knowledge
            
            return None
    
    def put(self, knowledge: KnowledgeItem) -> None:
        """ç¼“å­˜çŸ¥è¯†"""
        with self._lock:
            # å¦‚æœå·²å­˜åœ¨ï¼Œå…ˆç§»é™¤
            if knowledge.id in self._cache:
                self._remove(knowledge.id)
            
            # æ£€æŸ¥ç¼“å­˜å¤§å°
            while len(self._cache) >= self.max_size:
                if self._access_order:
                    oldest_id = self._access_order.popleft()
                    self._remove(oldest_id)
                else:
                    break
            
            # æ·»åŠ åˆ°ç¼“å­˜
            self._cache[knowledge.id] = (knowledge, datetime.now())
            self._access_order.append(knowledge.id)
    
    def remove(self, knowledge_id: str) -> None:
        """ç§»é™¤ç¼“å­˜"""
        with self._lock:
            self._remove(knowledge_id)
    
    def _remove(self, knowledge_id: str) -> None:
        """å†…éƒ¨ç§»é™¤æ–¹æ³•"""
        if knowledge_id in self._cache:
            del self._cache[knowledge_id]
        if knowledge_id in self._access_order:
            self._access_order.remove(knowledge_id)
    
    def clear(self) -> None:
        """æ¸…ç©ºç¼“å­˜"""
        with self._lock:
            self._cache.clear()
            self._access_order.clear()
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        with self._lock:
            return {
                'size': len(self._cache),
                'max_size': self.max_size,
                'ttl_seconds': self.ttl_seconds,
                'hit_rate': getattr(self, '_hit_count', 0) / max(getattr(self, '_total_requests', 1), 1)
            }


class KnowledgeValidator:
    """çŸ¥è¯†éªŒè¯å™¨"""
    
    def __init__(self):
        self.logger = logger
    
    async def validate_knowledge(self, knowledge: KnowledgeItem) -> Tuple[bool, float, Dict[str, Any]]:
        """éªŒè¯çŸ¥è¯†"""
        try:
            validation_details = {}
            total_score = 0.0
            weight_sum = 0.0
            
            # åŸºæœ¬ç»“æ„éªŒè¯
            structure_valid, structure_score = self._validate_structure(knowledge)
            validation_details['structure'] = {
                'valid': structure_valid,
                'score': structure_score,
                'weight': 0.3
            }
            total_score += structure_score * 0.3
            weight_sum += 0.3
            
            # å†…å®¹è´¨é‡éªŒè¯
            content_valid, content_score = self._validate_content(knowledge)
            validation_details['content'] = {
                'valid': content_valid,
                'score': content_score,
                'weight': 0.4
            }
            total_score += content_score * 0.4
            weight_sum += 0.4
            
            # å…ƒæ•°æ®éªŒè¯
            metadata_valid, metadata_score = self._validate_metadata(knowledge)
            validation_details['metadata'] = {
                'valid': metadata_valid,
                'score': metadata_score,
                'weight': 0.3
            }
            total_score += metadata_score * 0.3
            weight_sum += 0.3
            
            # è®¡ç®—æ€»åˆ†
            final_score = total_score / weight_sum if weight_sum > 0 else 0.0
            is_valid = structure_valid and content_valid and metadata_valid and final_score >= 0.6
            
            # æ›´æ–°çŸ¥è¯†çš„éªŒè¯çŠ¶æ€
            knowledge.metadata.validation_status = 'valid' if is_valid else 'invalid'
            knowledge.metadata.validation_score = final_score
            knowledge.metadata.validation_details = validation_details
            
            return is_valid, final_score, validation_details
            
        except Exception as e:
            logger.error(f"Failed to validate knowledge {knowledge.id}: {e}")
            return False, 0.0, {'error': str(e)}
    
    def _validate_structure(self, knowledge: KnowledgeItem) -> Tuple[bool, float]:
        """éªŒè¯ç»“æ„"""
        score = 0.0
        
        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        if knowledge.id:
            score += 0.2
        if knowledge.title:
            score += 0.2
        if knowledge.content is not None:
            score += 0.3
        if knowledge.type and knowledge.source:
            score += 0.2
        if knowledge.domain:
            score += 0.1
        
        return score >= 0.8, score
    
    def _validate_content(self, knowledge: KnowledgeItem) -> Tuple[bool, float]:
        """éªŒè¯å†…å®¹"""
        score = 0.0
        
        if knowledge.content is None:
            return False, 0.0
        
        # å†…å®¹é•¿åº¦æ£€æŸ¥
        if isinstance(knowledge.content, str):
            content_length = len(knowledge.content)
            if content_length > 10:
                score += 0.3
            if content_length > 100:
                score += 0.2
        elif isinstance(knowledge.content, (dict, list)):
            score += 0.5
        
        # æè¿°è´¨é‡
        if knowledge.description and len(knowledge.description) > 20:
            score += 0.2
        
        # å…³é”®è¯è´¨é‡
        if knowledge.keywords and len(knowledge.keywords) > 0:
            score += 0.3
        
        return score >= 0.6, score
    
    def _validate_metadata(self, knowledge: KnowledgeItem) -> Tuple[bool, float]:
        """éªŒè¯å…ƒæ•°æ®"""
        score = 0.0
        
        # æ—¶é—´æˆ³æ£€æŸ¥
        if knowledge.metadata.created_at:
            score += 0.2
        if knowledge.metadata.updated_at:
            score += 0.2
        
        # è´¨é‡æŒ‡æ ‡æ£€æŸ¥
        if 0 <= knowledge.metadata.confidence <= 1:
            score += 0.2
        if 0 <= knowledge.metadata.reliability <= 1:
            score += 0.2
        if 0 <= knowledge.metadata.accuracy <= 1:
            score += 0.2
        
        return score >= 0.6, score


class KnowledgeLifecycleManager:
    """çŸ¥è¯†ç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨"""
    
    def __init__(self, store: KnowledgeStoreInterface):
        self.store = store
        self.logger = logger
        self._cleanup_task: Optional[asyncio.Task] = None
        self._running = False
    
    async def start(self) -> None:
        """å¯åŠ¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
        if not self._running:
            self._running = True
            self._cleanup_task = asyncio.create_task(self._cleanup_loop())
            logger.info("Knowledge lifecycle manager started")
    
    async def stop(self) -> None:
        """åœæ­¢ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
        self._running = False
        if self._cleanup_task:
            self._cleanup_task.cancel()
            try:
                await self._cleanup_task
            except asyncio.CancelledError:
                pass
        logger.info("Knowledge lifecycle manager stopped")
    
    async def _cleanup_loop(self) -> None:
        """æ¸…ç†å¾ªç¯"""
        while self._running:
            try:
                await self._perform_cleanup()
                await asyncio.sleep(3600)  # æ¯å°æ—¶æ‰§è¡Œä¸€æ¬¡æ¸…ç†
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Error in cleanup loop: {e}")
                await asyncio.sleep(300)  # å‡ºé”™æ—¶ç­‰å¾…5åˆ†é’Ÿ
    
    async def _perform_cleanup(self) -> None:
        """æ‰§è¡Œæ¸…ç†"""
        try:
            # è·å–æ‰€æœ‰çŸ¥è¯†é¡¹
            all_knowledge = await self.store.get_all_knowledge()
            
            expired_count = 0
            obsolete_count = 0
            
            for knowledge in all_knowledge:
                # æ£€æŸ¥è¿‡æœŸ
                if self._is_expired(knowledge):
                    await self.store.delete_knowledge(knowledge.id)
                    expired_count += 1
                    continue
                
                # æ£€æŸ¥æ˜¯å¦è¿‡æ—¶
                if self._is_obsolete(knowledge):
                    knowledge.status = KnowledgeStatus.OBSOLETE
                    await self.store.update_knowledge(knowledge)
                    obsolete_count += 1
            
            if expired_count > 0 or obsolete_count > 0:
                logger.info(
                    f"Cleanup completed: {expired_count} expired, {obsolete_count} obsolete"
                )
                
        except Exception as e:
            logger.error(f"Failed to perform cleanup: {e}")
    
    def _is_expired(self, knowledge: KnowledgeItem) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¿‡æœŸ"""
        if not knowledge.metadata.expiry_date:
            return False
        
        try:
            expiry_date = datetime.fromisoformat(knowledge.metadata.expiry_date.replace('Z', '+00:00'))
            return datetime.now() > expiry_date
        except Exception:
            return False
    
    def _is_obsolete(self, knowledge: KnowledgeItem) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¿‡æ—¶"""
        if not knowledge.metadata.retention_period:
            return False
        
        try:
            created_date = datetime.fromisoformat(knowledge.metadata.created_at.replace('Z', '+00:00'))
            retention_days = knowledge.metadata.retention_period
            return datetime.now() > created_date + timedelta(days=retention_days)
        except Exception:
            return False


class KnowledgeManager(Component):
    """çŸ¥è¯†ç®¡ç†å™¨ - åŸºäºAgenticX Componentï¼Œä½¿ç”¨AgenticXå­˜å‚¨å’Œæ£€ç´¢ç»„ä»¶"""
    
    def __init__(
        self,
        config: Optional[Dict[str, Any]] = None,
        event_bus: Optional[EventBus] = None,
        memory: Optional[MemoryComponent] = None,
        embedding_provider: Optional[Any] = None
    ):
        super().__init__(name="knowledge_manager")
        
        self.logger = logger
        self.event_bus = event_bus or EventBus()
        self.memory = memory
        
        # åˆ›å»ºAgenticXé…ç½®
        database_config = config.get('database', {})
        self.agenticx_config = AgenticXConfig(
            storage_type=config.get('storage_type', 'milvus'),
            milvus_config=database_config.get('milvus'),
            postgres_config=database_config.get('postgres'),
            redis_config=database_config.get('redis'),
            vectorization_enabled=config.get('vectorization', {}).get('enabled', True),
            embedding_dimension=config.get('vectorization', {}).get('dimension', 1536),
            embedding_provider=config.get('embedding_provider', 'bailian'),
            embedding_config=config.get('embedding_config'),
            retrieval_type=config.get('retrieval_type', 'hybrid')
        )
        
        # åˆ›å»ºAgenticXçŸ¥è¯†ç®¡ç†å™¨
        self.agenticx_manager = AgenticXKnowledgeManager(self.agenticx_config)
        
        # è®¾ç½®embeddingæä¾›è€…ï¼ˆä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„ï¼Œå¦åˆ™ä½¿ç”¨é…ç½®ä¸­çš„ï¼‰
        if embedding_provider:
            self.embedding_provider = embedding_provider
        else:
            # ä»AgenticXç®¡ç†å™¨è·å–embeddingæä¾›è€…
            self.embedding_provider = self.agenticx_manager.embedding_provider
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_knowledge': 0,
            'cache_hits': 0,
            'cache_misses': 0,
            'validations_performed': 0,
            'validations_passed': 0,
            'sync_operations': 0,
            'last_sync': None
        }
        
        # åŒæ­¥é…ç½®
        self.sync_config = {
            'auto_sync': True,
            'sync_interval': 300,  # 5åˆ†é’Ÿ
            'batch_size': 100,
            'max_retries': 3
        }
        
        # äº‹ä»¶å›è°ƒ
        self.event_callbacks: Dict[str, List[Callable]] = defaultdict(list)
        
        # è¿è¡ŒçŠ¶æ€
        self._running = False
        self._sync_task: Optional[asyncio.Task] = None
        self._lock = threading.RLock()
    
    async def start(self) -> None:
        """å¯åŠ¨çŸ¥è¯†ç®¡ç†å™¨"""
        if not self._running:
            logger.info(f"ğŸš€ å¯åŠ¨çŸ¥è¯†ç®¡ç†å™¨...")
            self._running = True
            
            # åˆå§‹åŒ–AgenticXç®¡ç†å™¨
            logger.info(f"ğŸ”§ åˆå§‹åŒ– AgenticX ç®¡ç†å™¨...")
            await self.agenticx_manager.initialize()
            logger.info(f"âœ… AgenticX ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
            
            # å¯åŠ¨è‡ªåŠ¨åŒæ­¥
            if self.sync_config['auto_sync']:
                logger.info(f"â° å¯åŠ¨è‡ªåŠ¨åŒæ­¥ä»»åŠ¡ (é—´éš”: {self.sync_config['sync_interval']}ç§’)")
                self._sync_task = asyncio.create_task(self._sync_loop())
            else:
                logger.info(f"â„¹ï¸ è‡ªåŠ¨åŒæ­¥å·²ç¦ç”¨")
            
            # å‘å¸ƒå¯åŠ¨äº‹ä»¶
            await self._publish_event('manager_started', {'timestamp': get_iso_timestamp()})
            
            logger.info(f"ğŸ‰ çŸ¥è¯†ç®¡ç†å™¨å¯åŠ¨å®Œæˆ")
            logger.info(f"   - å­˜å‚¨ç±»å‹: {self.agenticx_config.storage_type}")
            logger.info(f"   - å‘é‡åŒ–: {'å¯ç”¨' if self.agenticx_config.vectorization_enabled else 'ç¦ç”¨'}")
            logger.info(f"   - æ£€ç´¢ç±»å‹: {self.agenticx_config.retrieval_type}")
    
    async def stop(self) -> None:
        """åœæ­¢çŸ¥è¯†ç®¡ç†å™¨"""
        logger.info(f"ğŸ›‘ åœæ­¢çŸ¥è¯†ç®¡ç†å™¨...")
        self._running = False
        
        # åœæ­¢åŒæ­¥ä»»åŠ¡
        if self._sync_task:
            logger.info(f"â¹ï¸ åœæ­¢è‡ªåŠ¨åŒæ­¥ä»»åŠ¡...")
            self._sync_task.cancel()
            try:
                await self._sync_task
                logger.info(f"âœ… è‡ªåŠ¨åŒæ­¥ä»»åŠ¡å·²åœæ­¢")
            except asyncio.CancelledError:
                logger.info(f"âœ… è‡ªåŠ¨åŒæ­¥ä»»åŠ¡å·²å–æ¶ˆ")
        
        # å…³é—­AgenticXç®¡ç†å™¨
        logger.info(f"ğŸ”§ å…³é—­ AgenticX ç®¡ç†å™¨...")
        await self.agenticx_manager.close()
        logger.info(f"âœ… AgenticX ç®¡ç†å™¨å·²å…³é—­")
        
        # å‘å¸ƒåœæ­¢äº‹ä»¶
        await self._publish_event('manager_stopped', {'timestamp': get_iso_timestamp()})
        
        logger.info(f"ğŸ çŸ¥è¯†ç®¡ç†å™¨å·²åœæ­¢")
    
    async def store_knowledge(
        self,
        knowledge: KnowledgeItem,
        validate: bool = True,
        cache: bool = True
    ) -> bool:
        """å­˜å‚¨çŸ¥è¯†"""
        try:
            logger.info(f"ğŸ“š å¼€å§‹å­˜å‚¨çŸ¥è¯†: {knowledge.id}")
            logger.info(f"   - æ ‡é¢˜: {knowledge.title}")
            logger.info(f"   - çŸ¥è¯†ç±»å‹: {knowledge.type.value}")
            logger.info(f"   - æ¥æº: {knowledge.source.value}")
            logger.info(f"   - é¢†åŸŸ: {knowledge.domain}")
            
            # å‘é‡åŒ–æ–‡æœ¬å†…å®¹
            vector = None
            if self.agenticx_config.vectorization_enabled:
                logger.info(f"ğŸ”„ å¼€å§‹å‘é‡åŒ–å¤„ç†...")
                text_content = self._extract_text_content(knowledge)
                logger.info(f"   - æå–æ–‡æœ¬å†…å®¹é•¿åº¦: {len(text_content)} å­—ç¬¦")
                
                if hasattr(self.embedding_provider, 'encode_text'):
                    logger.info(f"   - ä½¿ç”¨ encode_text æ–¹æ³•ç”Ÿæˆå‘é‡")
                    vector = await self.embedding_provider.encode_text(text_content)
                elif hasattr(self.embedding_provider, 'embed'):
                    logger.info(f"   - ä½¿ç”¨ embed æ–¹æ³•ç”Ÿæˆå‘é‡")
                    from .embedding_config import EmbeddingRequest, ContentType
                    request = EmbeddingRequest(content=text_content, content_type=ContentType.PURE_TEXT)
                    result = await self.embedding_provider.embed(request)
                    vector = result.embeddings[0] if result.embeddings else None
                else:
                    logger.warning(f"   - å‘é‡åŒ–æä¾›è€…ä¸æ”¯æŒæ–‡æœ¬ç¼–ç ")
                    vector = None
                
                if vector:
                    logger.info(f"âœ… å‘é‡ç”ŸæˆæˆåŠŸï¼Œç»´åº¦: {len(vector)}")
                else:
                    logger.warning(f"âš ï¸ å‘é‡ç”Ÿæˆå¤±è´¥")
            else:
                logger.info(f"â„¹ï¸ å‘é‡åŒ–åŠŸèƒ½å·²ç¦ç”¨")
            
            # ä½¿ç”¨AgenticXç®¡ç†å™¨å­˜å‚¨
            logger.info(f"ğŸ’¾ å¼€å§‹å­˜å‚¨åˆ°çŸ¥è¯†åº“...")
            success = await self.agenticx_manager.store_knowledge(knowledge, vector)
            
            if success:
                # æ›´æ–°ç»Ÿè®¡
                with self._lock:
                    self.stats['total_knowledge'] += 1
                
                # å‘å¸ƒäº‹ä»¶
                await self._publish_event('knowledge_stored', {
                    'knowledge_id': knowledge.id,
                    'type': knowledge.type.value,
                    'timestamp': get_iso_timestamp()
                })
                
                logger.info(f"ğŸ‰ çŸ¥è¯†å­˜å‚¨æˆåŠŸ: {knowledge.id}")
                logger.info(f"   - æ€»çŸ¥è¯†æ•°é‡: {self.stats['total_knowledge']}")
            else:
                logger.error(f"âŒ çŸ¥è¯†å­˜å‚¨å¤±è´¥: {knowledge.id}")
            
            return success
            
        except Exception as e:
            logger.error(f"ğŸ’¥ å­˜å‚¨çŸ¥è¯†æ—¶å‘ç”Ÿå¼‚å¸¸ {knowledge.id}: {e}")
            return False
    
    def _extract_text_content(self, knowledge: KnowledgeItem) -> str:
        """ä»çŸ¥è¯†é¡¹æå–æ–‡æœ¬å†…å®¹"""
        content_parts = []
        
        if knowledge.title:
            content_parts.append(knowledge.title)
        
        if knowledge.description:
            content_parts.append(knowledge.description)
        
        if knowledge.keywords:
            content_parts.append(" ".join(knowledge.keywords))
        
        if isinstance(knowledge.content, str):
            content_parts.append(knowledge.content)
        elif isinstance(knowledge.content, dict):
            for value in knowledge.content.values():
                if isinstance(value, str):
                    content_parts.append(value)
        
        return " ".join(content_parts)
    
    async def retrieve_knowledge(
        self,
        knowledge_id: str,
        use_cache: bool = True
    ) -> Optional[KnowledgeItem]:
        """æ£€ç´¢çŸ¥è¯†"""
        try:
            logger.info(f"ğŸ” å¼€å§‹æ£€ç´¢çŸ¥è¯†: {knowledge_id}")
            logger.info(f"   - ä½¿ç”¨ç¼“å­˜: {use_cache}")
            
            # ä½¿ç”¨AgenticXç®¡ç†å™¨æ£€ç´¢
            logger.info(f"ğŸ“– ä»çŸ¥è¯†åº“æ£€ç´¢...")
            knowledge = await self.agenticx_manager.retrieve_knowledge(knowledge_id)
            
            if knowledge:
                logger.info(f"âœ… çŸ¥è¯†æ£€ç´¢æˆåŠŸ: {knowledge_id}")
                logger.info(f"   - æ ‡é¢˜: {knowledge.title}")
                logger.info(f"   - ç±»å‹: {knowledge.type.value}")
                logger.info(f"   - çŠ¶æ€: {knowledge.status.value}")
                
                # å‘å¸ƒäº‹ä»¶
                await self._publish_event('knowledge_retrieved', {
                    'knowledge_id': knowledge_id,
                    'timestamp': get_iso_timestamp()
                })
            else:
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°çŸ¥è¯†: {knowledge_id}")
            
            return knowledge
            
        except Exception as e:
            logger.error(f"ğŸ’¥ æ£€ç´¢çŸ¥è¯†æ—¶å‘ç”Ÿå¼‚å¸¸ {knowledge_id}: {e}")
            return None
    
    async def update_knowledge(
        self,
        knowledge: KnowledgeItem,
        validate: bool = True
    ) -> bool:
        """æ›´æ–°çŸ¥è¯†"""
        try:
            # éªŒè¯çŸ¥è¯†
            if validate and self.validator:
                is_valid, score, details = await self.validator.validate_knowledge(knowledge)
                self.stats['validations_performed'] += 1
                
                if is_valid:
                    self.stats['validations_passed'] += 1
                else:
                    logger.warning(f"Knowledge validation failed: {knowledge.id}")
                    return False
            
            # æ›´æ–°å­˜å‚¨
            success = await self.store.update_knowledge(knowledge)
            
            if success:
                # æ›´æ–°ç¼“å­˜
                self.cache.put(knowledge)
                
                # å‘å¸ƒäº‹ä»¶
                await self._publish_event('knowledge_updated', {
                    'knowledge_id': knowledge.id,
                    'version': knowledge.metadata.version,
                    'timestamp': get_iso_timestamp()
                })
                
                logger.debug(f"Updated knowledge: {knowledge.id}")
            
            return success
            
        except Exception as e:
            logger.error(f"Failed to update knowledge {knowledge.id}: {e}")
            return False
    
    async def delete_knowledge(self, knowledge_id: str) -> bool:
        """åˆ é™¤çŸ¥è¯†"""
        try:
            # ä»å­˜å‚¨åˆ é™¤
            success = await self.store.delete_knowledge(knowledge_id)
            
            if success:
                # ä»ç¼“å­˜åˆ é™¤
                self.cache.remove(knowledge_id)
                
                # æ›´æ–°ç»Ÿè®¡
                with self._lock:
                    self.stats['total_knowledge'] = max(0, self.stats['total_knowledge'] - 1)
                
                # å‘å¸ƒäº‹ä»¶
                await self._publish_event('knowledge_deleted', {
                    'knowledge_id': knowledge_id,
                    'timestamp': get_iso_timestamp()
                })
                
                logger.debug(f"Deleted knowledge: {knowledge_id}")
            
            return success
            
        except Exception as e:
            logger.error(f"Failed to delete knowledge {knowledge_id}: {e}")
            return False
    
    async def query_knowledge(self, request: QueryRequest) -> QueryResult:
        """æŸ¥è¯¢çŸ¥è¯†"""
        try:
            logger.info(f"ğŸ” å¼€å§‹æŸ¥è¯¢çŸ¥è¯†: {request.id}")
            logger.info(f"   - æŸ¥è¯¢æ–‡æœ¬: {request.query_text[:100]}..." if request.query_text and len(request.query_text) > 100 else f"   - æŸ¥è¯¢æ–‡æœ¬: {request.query_text}")
            logger.info(f"   - æŸ¥è¯¢ç±»å‹: {request.query_type}")
            logger.info(f"   - é™åˆ¶æ•°é‡: {request.limit}")
            
            # å‘é‡åŒ–æŸ¥è¯¢æ–‡æœ¬ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            query_vector = None
            if self.agenticx_config.vectorization_enabled and request.query_text:
                logger.info(f"ğŸ”„ å¼€å§‹æŸ¥è¯¢æ–‡æœ¬å‘é‡åŒ–...")
                if hasattr(self.embedding_provider, 'encode_text'):
                    logger.info(f"   - ä½¿ç”¨ encode_text æ–¹æ³•")
                    query_vector = await self.embedding_provider.encode_text(request.query_text)
                elif hasattr(self.embedding_provider, 'embed'):
                    logger.info(f"   - ä½¿ç”¨ embed æ–¹æ³•")
                    from .embedding_config import EmbeddingRequest, ContentType
                    request_obj = EmbeddingRequest(content=request.query_text, content_type=ContentType.PURE_TEXT)
                    result = await self.embedding_provider.embed(request_obj)
                    query_vector = result.embeddings[0] if result.embeddings else None
                else:
                    logger.warning(f"   - å‘é‡åŒ–æä¾›è€…ä¸æ”¯æŒæŸ¥è¯¢å‘é‡åŒ–")
                    query_vector = None
                
                if query_vector:
                    logger.info(f"âœ… æŸ¥è¯¢å‘é‡ç”ŸæˆæˆåŠŸï¼Œç»´åº¦: {len(query_vector)}")
                else:
                    logger.warning(f"âš ï¸ æŸ¥è¯¢å‘é‡ç”Ÿæˆå¤±è´¥")
            else:
                logger.info(f"â„¹ï¸ è·³è¿‡å‘é‡åŒ–ï¼ˆåŠŸèƒ½ç¦ç”¨æˆ–æ— æŸ¥è¯¢æ–‡æœ¬ï¼‰")
            
            # ä½¿ç”¨AgenticXç®¡ç†å™¨æŸ¥è¯¢
            logger.info(f"ğŸ” æ‰§è¡ŒçŸ¥è¯†åº“æŸ¥è¯¢...")
            result = await self.agenticx_manager.query_knowledge(request, query_vector)
            
            logger.info(f"âœ… æŸ¥è¯¢å®Œæˆ: {request.id}")
            logger.info(f"   - æ‰¾åˆ°ç»“æœ: {len(result.items)} æ¡")
            logger.info(f"   - æ‰§è¡Œæ—¶é—´: {result.execution_time:.3f} ç§’")
            
            # è®°å½•å‰å‡ ä¸ªç»“æœçš„è¯¦ç»†ä¿¡æ¯
            for i, item in enumerate(result.items[:3]):
                logger.info(f"   - ç»“æœ {i+1}: {item.title} (ç›¸ä¼¼åº¦: {getattr(item, 'similarity_score', 'N/A')})")
            
            # å‘å¸ƒäº‹ä»¶
            await self._publish_event('knowledge_queried', {
                'request_id': request.id,
                'result_count': len(result.items),
                'execution_time': result.execution_time,
                'timestamp': get_iso_timestamp()
            })
            
            return result
            
        except Exception as e:
            logger.error(f"ğŸ’¥ æŸ¥è¯¢çŸ¥è¯†æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
            return QueryResult(request_id=request.id)
    
    async def sync_knowledge(self, request: SyncRequest) -> SyncResult:
        """åŒæ­¥çŸ¥è¯†"""
        start_time = datetime.now()
        
        try:
            with self._lock:
                self.stats['sync_operations'] += 1
            
            # æ‰§è¡ŒåŒæ­¥é€»è¾‘
            synced_count = 0
            failed_count = 0
            conflicts = []
            
            # è¿™é‡Œå¯ä»¥å®ç°å…·ä½“çš„åŒæ­¥é€»è¾‘
            # ä¾‹å¦‚ï¼šä¸è¿œç¨‹çŸ¥è¯†åº“åŒæ­¥ã€åˆå¹¶å†²çªç­‰
            
            execution_time = (datetime.now() - start_time).total_seconds()
            
            result = SyncResult(
                request_id=request.id,
                success=failed_count == 0,
                synced_count=synced_count,
                failed_count=failed_count,
                execution_time=execution_time
            )
            
            # æ›´æ–°ç»Ÿè®¡
            with self._lock:
                self.stats['last_sync'] = get_iso_timestamp()
            
            # å‘å¸ƒäº‹ä»¶
            await self._publish_event('knowledge_synced', {
                'request_id': request.id,
                'synced_count': synced_count,
                'failed_count': failed_count,
                'timestamp': get_iso_timestamp()
            })
            
            return result
            
        except Exception as e:
            logger.error(f"Failed to sync knowledge: {e}")
            execution_time = (datetime.now() - start_time).total_seconds()
            return SyncResult(
                request_id=request.id,
                success=False,
                execution_time=execution_time,
                errors=[str(e)]
            )
    
    async def get_knowledge_stats(self) -> Dict[str, Any]:
        """è·å–çŸ¥è¯†ç»Ÿè®¡"""
        try:
            # è·å–å­˜å‚¨ç»Ÿè®¡
            total_count = await self.store.get_knowledge_count()
            
            # è·å–ç¼“å­˜ç»Ÿè®¡
            cache_stats = self.cache.get_stats()
            
            # åˆå¹¶ç»Ÿè®¡ä¿¡æ¯
            stats = {
                **self.stats,
                'total_knowledge': total_count,
                'cache_stats': cache_stats,
                'timestamp': get_iso_timestamp()
            }
            
            return stats
            
        except Exception as e:
            logger.error(f"Failed to get knowledge stats: {e}")
            return {}
    
    def register_event_callback(self, event_type: str, callback: Callable) -> None:
        """æ³¨å†Œäº‹ä»¶å›è°ƒ"""
        self.event_callbacks[event_type].append(callback)
    
    def unregister_event_callback(self, event_type: str, callback: Callable) -> None:
        """å–æ¶ˆæ³¨å†Œäº‹ä»¶å›è°ƒ"""
        if callback in self.event_callbacks[event_type]:
            self.event_callbacks[event_type].remove(callback)
    
    async def _publish_event(self, event_type: str, data: Dict[str, Any]) -> None:
        """å‘å¸ƒäº‹ä»¶"""
        try:
            # è°ƒç”¨æ³¨å†Œçš„å›è°ƒ
            for callback in self.event_callbacks[event_type]:
                try:
                    if asyncio.iscoroutinefunction(callback):
                        await callback(event_type, data)
                    else:
                        callback(event_type, data)
                except Exception as e:
                    logger.error(f"Error in event callback: {e}")
            
            # å‘å¸ƒåˆ°EventBus - å¢å¼ºå¥å£®æ€§æ£€æŸ¥
            event_bus = getattr(self, 'event_bus', None)  # å®‰å…¨è·å–event_bus
            if event_bus and hasattr(event_bus, 'publish'):
                try:
                    event = Event(
                        type=f'knowledge_{event_type}',
                        source='knowledge_manager',
                        data=data
                    )
                    await event_bus.publish_async(event)
                except Exception as publish_error:
                    # å¦‚æœå‘å¸ƒå¤±è´¥ï¼Œè®°å½•ä½†ä¸æŠ›å‡ºå¼‚å¸¸
                    logger.debug(f"Event publish failed for {event_type}: {publish_error}")
                
        except Exception as e:
            logger.error(f"Failed to publish event {event_type}: {e}")
    
    async def _sync_loop(self) -> None:
        """åŒæ­¥å¾ªç¯"""
        while self._running:
            try:
                # åˆ›å»ºåŒæ­¥è¯·æ±‚
                sync_request = SyncRequest(
                    id=str(uuid4()),
                    source_agent='auto_sync',
                    sync_type='incremental'
                )
                
                # æ‰§è¡ŒåŒæ­¥
                await self.sync_knowledge(sync_request)
                
                # ç­‰å¾…ä¸‹æ¬¡åŒæ­¥
                await asyncio.sleep(self.sync_config['sync_interval'])
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Error in sync loop: {e}")
                await asyncio.sleep(60)  # å‡ºé”™æ—¶ç­‰å¾…1åˆ†é’Ÿ
    
    async def clear_cache(self) -> None:
        """æ¸…ç©ºç¼“å­˜"""
        self.cache.clear()
        logger.info("Knowledge cache cleared")
    
    async def rebuild_indexes(self) -> bool:
        """é‡å»ºç´¢å¼•"""
        try:
            # è¿™é‡Œå¯ä»¥å®ç°ç´¢å¼•é‡å»ºé€»è¾‘
            # ä¾‹å¦‚ï¼šé‡æ–°æ„å»ºæœç´¢ç´¢å¼•ã€å…³ç³»ç´¢å¼•ç­‰
            
            logger.info("Knowledge indexes rebuilt")
            return True
            
        except Exception as e:
            logger.error(f"Failed to rebuild indexes: {e}")
            return False
    
    async def export_knowledge(
        self,
        filters: Optional[Dict[str, Any]] = None,
        format: str = 'json'
    ) -> Optional[str]:
        """å¯¼å‡ºçŸ¥è¯†"""
        try:
            # æŸ¥è¯¢çŸ¥è¯†
            query_request = QueryRequest(
                id=str(uuid4()),
                filters=filters or {},
                limit=10000  # å¤§æ‰¹é‡å¯¼å‡º
            )
            
            result = await self.query_knowledge(query_request)
            
            if format == 'json':
                # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
                export_data = []
                for knowledge in result.items:
                    knowledge_dict = {
                        'id': knowledge.id,
                        'type': knowledge.type.value,
                        'source': knowledge.source.value,
                        'status': knowledge.status.value,
                        'title': knowledge.title,
                        'content': knowledge.content,
                        'description': knowledge.description,
                        'keywords': list(knowledge.keywords),
                        'context': knowledge.context,
                        'domain': knowledge.domain,
                        'scope': knowledge.scope,
                        'metadata': knowledge.metadata.__dict__,
                        'parent_id': knowledge.parent_id,
                        'children_ids': list(knowledge.children_ids),
                        'related_ids': list(knowledge.related_ids),
                        'schema_version': knowledge.schema_version,
                        'data_format': knowledge.data_format,
                        'encoding': knowledge.encoding
                    }
                    export_data.append(knowledge_dict)
                
                return json.dumps(export_data, indent=2, ensure_ascii=False)
            
            else:
                raise ValueError(f"Unsupported export format: {format}")
                
        except Exception as e:
            logger.error(f"Failed to export knowledge: {e}")
            return None
    
    async def import_knowledge(
        self,
        data: str,
        format: str = 'json',
        validate: bool = True
    ) -> Tuple[int, int]:
        """å¯¼å…¥çŸ¥è¯†"""
        try:
            imported_count = 0
            failed_count = 0
            
            if format == 'json':
                import_data = json.loads(data)
                
                for item_dict in import_data:
                    try:
                        # é‡å»ºçŸ¥è¯†å¯¹è±¡
                        metadata = KnowledgeMetadata(**item_dict['metadata'])
                        
                        knowledge = KnowledgeItem(
                            id=item_dict['id'],
                            type=KnowledgeType(item_dict['type']),
                            source=KnowledgeSource(item_dict['source']),
                            status=KnowledgeStatus(item_dict['status']),
                            title=item_dict['title'],
                            content=item_dict['content'],
                            description=item_dict['description'],
                            keywords=set(item_dict['keywords']),
                            context=item_dict['context'],
                            domain=item_dict['domain'],
                            scope=item_dict['scope'],
                            metadata=metadata,
                            parent_id=item_dict.get('parent_id'),
                            children_ids=set(item_dict.get('children_ids', [])),
                            related_ids=set(item_dict.get('related_ids', [])),
                            schema_version=item_dict.get('schema_version', '1.0'),
                            data_format=item_dict.get('data_format', 'json'),
                            encoding=item_dict.get('encoding', 'utf-8')
                        )
                        
                        # å­˜å‚¨çŸ¥è¯†
                        success = await self.store_knowledge(knowledge, validate=validate)
                        
                        if success:
                            imported_count += 1
                        else:
                            failed_count += 1
                            
                    except Exception as e:
                        logger.error(f"Failed to import knowledge item: {e}")
                        failed_count += 1
            
            else:
                raise ValueError(f"Unsupported import format: {format}")
            
            logger.info(f"Import completed: {imported_count} success, {failed_count} failed")
            return imported_count, failed_count
            
        except Exception as e:
            logger.error(f"Failed to import knowledge: {e}")
            return 0, 0
    
    def update_sync_config(self, config: Dict[str, Any]) -> None:
        """æ›´æ–°åŒæ­¥é…ç½®"""
        self.sync_config.update(config)
        logger.info(f"Sync config updated: {config}")
    
    def get_sync_config(self) -> Dict[str, Any]:
        """è·å–åŒæ­¥é…ç½®"""
        return self.sync_config.copy()